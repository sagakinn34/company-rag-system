"""
Notion ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« - Streamlitå¯¾å¿œç‰ˆ
Streamlit Secrets ã‹ã‚‰èªè¨¼æƒ…å ±ã‚’å–å¾—ã—ã€Notion ã‹ã‚‰å„ç¨®ãƒšãƒ¼ã‚¸ã¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’å–å¾—
"""

import os
import json
import time
from typing import List, Dict, Optional
import requests
import streamlit as st

class NotionProcessor:
    def __init__(self):
        """
        Notion ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ã‚’åˆæœŸåŒ– - Streamlitç’°å¢ƒå¯¾å¿œç‰ˆ
        """
        # Streamlit Secretsã‹ã‚‰èªè¨¼æƒ…å ±ã‚’å–å¾—
        try:
            self.notion_token = st.secrets["NOTION_TOKEN"]
            if not self.notion_token:
                raise ValueError("NOTION_TOKEN ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        except KeyError:
            raise ValueError("Streamlit Secretsã«NOTION_TOKENãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        self.base_url = "https://api.notion.com/v1"
        self.headers = {
            "Authorization": f"Bearer {self.notion_token}",
            "Notion-Version": "2022-06-28",
            "Content-Type": "application/json"
        }
        
        st.info("âœ… NotionProcessoråˆæœŸåŒ–å®Œäº†")
    
    def search_pages(self, query: str = "", page_size: int = 100) -> List[Dict]:
        """
        Notion ãƒšãƒ¼ã‚¸ã‚’æ¤œç´¢
        
        Args:
            query (str): æ¤œç´¢ã‚¯ã‚¨ãƒª
            page_size (int): å–å¾—ãƒšãƒ¼ã‚¸æ•°
            
        Returns:
            List[Dict]: ãƒšãƒ¼ã‚¸æƒ…å ±ã®ãƒªã‚¹ãƒˆ
        """
        try:
            url = f"{self.base_url}/search"
            payload = {
                "page_size": page_size,
                "filter": {
                    "property": "object",
                    "value": "page"
                }
            }
            
            if query:
                payload["query"] = query
            
            response = requests.post(url, headers=self.headers, json=payload)
            response.raise_for_status()
            
            data = response.json()
            pages = data.get("results", [])
            
            st.info(f"ğŸ“„ {len(pages)} ä»¶ã®Notionãƒšãƒ¼ã‚¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
            return pages
            
        except Exception as e:
            st.error(f"âŒ Notionãƒšãƒ¼ã‚¸æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def search_databases(self, query: str = "", page_size: int = 100) -> List[Dict]:
        """
        Notion ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ¤œç´¢
        
        Args:
            query (str): æ¤œç´¢ã‚¯ã‚¨ãƒª
            page_size (int): å–å¾—ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ•°
            
        Returns:
            List[Dict]: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æƒ…å ±ã®ãƒªã‚¹ãƒˆ
        """
        try:
            url = f"{self.base_url}/search"
            payload = {
                "page_size": page_size,
                "filter": {
                    "property": "object",
                    "value": "database"
                }
            }
            
            if query:
                payload["query"] = query
            
            response = requests.post(url, headers=self.headers, json=payload)
            response.raise_for_status()
            
            data = response.json()
            databases = data.get("results", [])
            
            st.info(f"ğŸ—‚ï¸ {len(databases)} ä»¶ã®Notionãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
            return databases
            
        except Exception as e:
            st.error(f"âŒ Notionãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def get_page_content(self, page_id: str) -> str:
        """
        ãƒšãƒ¼ã‚¸ã®å†…å®¹ã‚’å–å¾—
        
        Args:
            page_id (str): ãƒšãƒ¼ã‚¸ID
            
        Returns:
            str: ãƒšãƒ¼ã‚¸ã®ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹
        """
        try:
            # ãƒšãƒ¼ã‚¸ã®åŸºæœ¬æƒ…å ±ã‚’å–å¾—
            page_url = f"{self.base_url}/pages/{page_id}"
            page_response = requests.get(page_url, headers=self.headers)
            page_response.raise_for_status()
            page_data = page_response.json()
            
            # ãƒšãƒ¼ã‚¸ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—
            title = ""
            if "properties" in page_data:
                for prop_key, prop_value in page_data["properties"].items():
                    if prop_value.get("type") == "title":
                        title_list = prop_value.get("title", [])
                        if title_list:
                            title = "".join([t.get("plain_text", "") for t in title_list])
                        break
            
            # ãƒšãƒ¼ã‚¸ã®å†…å®¹ï¼ˆãƒ–ãƒ­ãƒƒã‚¯ï¼‰ã‚’å–å¾—
            blocks_url = f"{self.base_url}/blocks/{page_id}/children"
            blocks_response = requests.get(blocks_url, headers=self.headers)
            blocks_response.raise_for_status()
            blocks_data = blocks_response.json()
            
            # ãƒ–ãƒ­ãƒƒã‚¯ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
            content = self.extract_text_from_blocks(blocks_data.get("results", []))
            
            # ã‚¿ã‚¤ãƒˆãƒ«ã¨å†…å®¹ã‚’çµåˆ
            full_content = f"{title}\n\n{content}" if title else content
            
            return full_content.strip()
            
        except Exception as e:
            st.error(f"âŒ ãƒšãƒ¼ã‚¸å†…å®¹å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return ""
    
    def extract_text_from_blocks(self, blocks: List[Dict]) -> str:
        """
        ãƒ–ãƒ­ãƒƒã‚¯ãƒªã‚¹ãƒˆã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
        
        Args:
            blocks (List[Dict]): ãƒ–ãƒ­ãƒƒã‚¯ã®ãƒªã‚¹ãƒˆ
            
        Returns:
            str: æŠ½å‡ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ
        """
        text = ""
        
        for block in blocks:
            block_type = block.get("type", "")
            block_data = block.get(block_type, {})
            
            # ãƒ†ã‚­ã‚¹ãƒˆç³»ãƒ–ãƒ­ãƒƒã‚¯ã®å‡¦ç†
            if block_type in ["paragraph", "heading_1", "heading_2", "heading_3", "bulleted_list_item", "numbered_list_item"]:
                rich_text = block_data.get("rich_text", [])
                block_text = "".join([t.get("plain_text", "") for t in rich_text])
                if block_text:
                    text += block_text + "\n"
            
            # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã®å‡¦ç†
            elif block_type == "code":
                rich_text = block_data.get("rich_text", [])
                code_text = "".join([t.get("plain_text", "") for t in rich_text])
                if code_text:
                    text += f"```\n{code_text}\n```\n"
            
            # å¼•ç”¨ãƒ–ãƒ­ãƒƒã‚¯ã®å‡¦ç†
            elif block_type == "quote":
                rich_text = block_data.get("rich_text", [])
                quote_text = "".join([t.get("plain_text", "") for t in rich_text])
                if quote_text:
                    text += f"> {quote_text}\n"
            
            # åŒºåˆ‡ã‚Šç·š
            elif block_type == "divider":
                text += "---\n"
            
            # å­ãƒ–ãƒ­ãƒƒã‚¯ãŒã‚ã‚‹å ´åˆã¯å†å¸°çš„ã«å‡¦ç†
            if "children" in block:
                child_text = self.extract_text_from_blocks(block["children"])
                text += child_text
        
        return text
    
    def get_database_content(self, database_id: str) -> str:
        """
        ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å†…å®¹ã‚’å–å¾—
        
        Args:
            database_id (str): ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ID
            
        Returns:
            str: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹
        """
        try:
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åŸºæœ¬æƒ…å ±ã‚’å–å¾—
            db_url = f"{self.base_url}/databases/{database_id}"
            db_response = requests.get(db_url, headers=self.headers)
            db_response.raise_for_status()
            db_data = db_response.json()
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ã‚¿ã‚¤ãƒˆãƒ«
            title = ""
            if "title" in db_data:
                title_list = db_data["title"]
                title = "".join([t.get("plain_text", "") for t in title_list])
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ãƒšãƒ¼ã‚¸ã‚’å–å¾—
            pages_url = f"{self.base_url}/databases/{database_id}/query"
            pages_response = requests.post(pages_url, headers=self.headers, json={})
            pages_response.raise_for_status()
            pages_data = pages_response.json()
            
            # å„ãƒšãƒ¼ã‚¸ã®å†…å®¹ã‚’å–å¾—
            content = f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹: {title}\n\n"
            
            for page in pages_data.get("results", []):
                page_id = page["id"]
                page_content = self.get_page_content(page_id)
                if page_content:
                    content += f"--- ãƒšãƒ¼ã‚¸ ---\n{page_content}\n\n"
            
            return content.strip()
            
        except Exception as e:
            st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å†…å®¹å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return ""
    
    def get_all_pages(self) -> List[Dict]:
        """
        å…¨ã¦ã®Notionã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å‡¦ç†ã—ã¦RAGç”¨ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå½¢å¼ã§è¿”ã™
        
        Returns:
            List[Dict]: å‡¦ç†ã•ã‚ŒãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ãƒªã‚¹ãƒˆ
        """
        st.info("ğŸ” Notion ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å‡¦ç†ã‚’é–‹å§‹...")
        
        documents = []
        
        # ãƒšãƒ¼ã‚¸ã‚’å–å¾—ãƒ»å‡¦ç†
        pages = self.search_pages()
        for page in pages:
            try:
                content = self.get_page_content(page["id"])
                if content:
                    # ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—
                    title = "Untitled"
                    if "properties" in page:
                        for prop_key, prop_value in page["properties"].items():
                            if prop_value.get("type") == "title":
                                title_list = prop_value.get("title", [])
                                if title_list:
                                    title = "".join([t.get("plain_text", "") for t in title_list])
                                break
                    
                    document = {
                        'id': f"notion_page_{page['id']}",
                        'title': title,
                        'content': content,
                        'source': 'notion',
                        'type': 'page',
                        'created_time': page.get('created_time', ''),
                        'last_edited_time': page.get('last_edited_time', ''),
                        'url': page.get('url', '')
                    }
                    documents.append(document)
                    st.success(f"âœ… Notionãƒšãƒ¼ã‚¸å‡¦ç†æˆåŠŸ: {title} ({len(content)} æ–‡å­—)")
            except Exception as e:
                st.error(f"âŒ ãƒšãƒ¼ã‚¸å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                continue
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’å–å¾—ãƒ»å‡¦ç†
        databases = self.search_databases()
        for database in databases:
            try:
                content = self.get_database_content(database["id"])
                if content:
                    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—
                    title = "Untitled Database"
                    if "title" in database:
                        title_list = database["title"]
                        if title_list:
                            title = "".join([t.get("plain_text", "") for t in title_list])
                    
                    document = {
                        'id': f"notion_db_{database['id']}",
                        'title': title,
                        'content': content,
                        'source': 'notion',
                        'type': 'database',
                        'created_time': database.get('created_time', ''),
                        'last_edited_time': database.get('last_edited_time', ''),
                        'url': database.get('url', '')
                    }
                    documents.append(document)
                    st.success(f"âœ… Notionãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å‡¦ç†æˆåŠŸ: {title} ({len(content)} æ–‡å­—)")
            except Exception as e:
                st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                continue
        
        st.success(f"ğŸ‰ Notion å‡¦ç†å®Œäº†: {len(documents)} ä»¶ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ")
        return documents
