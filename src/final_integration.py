import sys
import os
import streamlit as st
import gc
import time

# çµ¶å¯¾ãƒ‘ã‚¹ã§srcãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¿½åŠ 
current_dir = os.path.dirname(os.path.abspath(__file__))
src_path = os.path.join(current_dir, '..', 'src') if 'src' not in current_dir else current_dir
sys.path.insert(0, src_path)

def run_data_integration():
    """æœ€é©åŒ–ç‰ˆãƒ‡ãƒ¼ã‚¿çµ±åˆï¼ˆå®Ÿç”¨æ€§ã¨å¯ç”¨æ€§ã®ãƒãƒ©ãƒ³ã‚¹ï¼‰"""
    
    # çµ±åˆé–‹å§‹è¡¨ç¤º
    st.info("âš–ï¸ æœ€é©åŒ–ãƒ‡ãƒ¼ã‚¿çµ±åˆã‚’é–‹å§‹...")
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–
    start_time = time.time()
    
    try:
        documents = []
        
        # === æœ€é©åŒ–è¨­å®š ===
        NOTION_OPTIMIZED = 150    # 300 â†’ 150 (50%å‰Šæ¸›)
        GDRIVE_OPTIMIZED = 100    # 200 â†’ 100 (50%å‰Šæ¸›)
        CONTENT_MAX_CHARS = 2000  # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æ–‡å­—æ•°åˆ¶é™
        
        # 1. Notionæœ€é©åŒ–å‡¦ç†
        status_text.text("ğŸ“ Notionæœ€é©åŒ–å–å¾—ä¸­...")
        progress_bar.progress(20)
        
        try:
            notion_token = st.secrets.get("NOTION_TOKEN")
            if notion_token:
                st.info("ğŸ“ NOTION_TOKEN: âœ… è¨­å®šæ¸ˆã¿")
                
                from notion_processor import NotionProcessor
                st.success("ğŸ“ NotionProcessor ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
                
                notion = NotionProcessor()
                st.success("ğŸ“ NotionProcessor ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆæˆåŠŸ")
                
                # æœ€é©åŒ–å–å¾—å®Ÿè¡Œ
                notion_docs = notion.get_all_pages()
                st.info(f"ğŸ“ Notionæœ€é©åŒ–å–å¾—çµæœ: {len(notion_docs) if notion_docs else 0}ä»¶")
                
                if notion_docs:
                    documents.extend(notion_docs)
                    st.success(f"âœ… Notionæœ€é©åŒ–å–å¾—æˆåŠŸ: {len(notion_docs)}ä»¶")
                    
                    # è©³ç´°å†…è¨³è¡¨ç¤º
                    with st.expander("ğŸ“Š Notionå–å¾—è©³ç´°"):
                        notion_types = {}
                        for doc in notion_docs:
                            doc_type = doc.get('type', 'ä¸æ˜')
                            notion_types[doc_type] = notion_types.get(doc_type, 0) + 1
                        
                        for doc_type, count in notion_types.items():
                            st.write(f"- {doc_type}: {count}ä»¶")
                else:
                    st.warning("âš ï¸ Notionãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
            else:
                st.error("âŒ NOTION_TOKENãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
                
        except Exception as e:
            st.error(f"âŒ Notionå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        
        # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        gc.collect()
        
        # 2. Google Driveæœ€é©åŒ–å‡¦ç†
        status_text.text("ğŸ“‚ Google Driveæœ€é©åŒ–å–å¾—ä¸­...")
        progress_bar.progress(50)
        
        try:
            gdrive_creds = st.secrets.get("GOOGLE_DRIVE_CREDENTIALS")
            
            st.info("ğŸ” === Google Driveæœ€é©åŒ–è¨ºæ–­é–‹å§‹ ===")
            
            if gdrive_creds:
                st.success("ğŸ“‚ GOOGLE_DRIVE_CREDENTIALS: âœ… è¨­å®šæ¸ˆã¿")
                
                # èªè¨¼æƒ…å ±ã®è©³ç´°ãƒã‚§ãƒƒã‚¯
                if hasattr(gdrive_creds, '_data'):
                    creds_dict = dict(gdrive_creds._data)
                else:
                    creds_dict = dict(gdrive_creds)
                
                # å¿…è¦ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®å­˜åœ¨ç¢ºèª
                required_fields = ['type', 'project_id', 'private_key_id', 'private_key', 'client_email']
                missing_fields = [field for field in required_fields if field not in creds_dict]
                
                if missing_fields:
                    st.error(f"âŒ å¿…è¦ãªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒä¸è¶³: {missing_fields}")
                else:
                    st.success("âœ… å¿…è¦ãªèªè¨¼ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒå…¨ã¦å­˜åœ¨")
                
                # Google Drive Processorï¼ˆæœ€é©åŒ–ç‰ˆï¼‰ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ»åˆæœŸåŒ–
                try:
                    from gdrive_processor import GoogleDriveProcessor
                    st.success("ğŸ“‚ GoogleDriveProcessorï¼ˆæœ€é©åŒ–ç‰ˆï¼‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
                    
                    # ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ
                    gdrive = GoogleDriveProcessor()
                    st.success("ğŸ“‚ GoogleDriveProcessorï¼ˆæœ€é©åŒ–ç‰ˆï¼‰ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆæˆåŠŸ")
                    
                    # ã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–ç¢ºèª
                    if gdrive.service:
                        st.success("âœ… Google Drive APIã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–æˆåŠŸ")
                        
                        # æ¥ç¶šãƒ†ã‚¹ãƒˆ
                        try:
                            test_result = gdrive.service.files().list(pageSize=1).execute()
                            test_files = test_result.get('files', [])
                            st.success(f"âœ… æ¥ç¶šãƒ†ã‚¹ãƒˆæˆåŠŸ: {len(test_files)}ä»¶ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½")
                            
                            # æœ€é©åŒ–ç‰ˆãƒ•ã‚¡ã‚¤ãƒ«å–å¾—å®Ÿè¡Œ
                            st.info("ğŸ“‚ æœ€é©åŒ–ç‰ˆãƒ•ã‚¡ã‚¤ãƒ«å–å¾—ä¸­ï¼ˆ100ä»¶ä¸Šé™ãƒ»åŠ¹ç‡é‡è¦–ï¼‰...")
                            gdrive_docs = gdrive.get_all_files()
                            st.info(f"ğŸ“‚ Google Driveæœ€é©åŒ–å–å¾—çµæœ: {len(gdrive_docs) if gdrive_docs else 0}ä»¶")
                            
                            if gdrive_docs:
                                documents.extend(gdrive_docs)
                                st.success(f"âœ… Google Driveæœ€é©åŒ–å–å¾—æˆåŠŸ: {len(gdrive_docs)}ä»¶")
                                
                                # è©³ç´°å†…è¨³è¡¨ç¤º
                                with st.expander("ğŸ“‹ Google Driveå–å¾—è©³ç´°"):
                                    gdrive_categories = {}
                                    gdrive_priorities = {}
                                    
                                    for doc in gdrive_docs:
                                        category = doc.get('category', 'ä¸æ˜')
                                        priority = doc.get('priority', 'ä¸æ˜')
                                        
                                        gdrive_categories[category] = gdrive_categories.get(category, 0) + 1
                                        gdrive_priorities[priority] = gdrive_priorities.get(priority, 0) + 1
                                    
                                    st.write("**ã‚«ãƒ†ã‚´ãƒªåˆ¥:**")
                                    for category, count in gdrive_categories.items():
                                        st.write(f"- {category}: {count}ä»¶")
                                    
                                    st.write("**é‡è¦åº¦åˆ¥:**")
                                    for priority, count in gdrive_priorities.items():
                                        st.write(f"- {priority}: {count}ä»¶")
                            else:
                                st.warning("âš ï¸ Google Driveãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
                                st.info("ğŸ’¡ è€ƒãˆã‚‰ã‚Œã‚‹åŸå› :")
                                st.write("- Service Accountã«ãƒ•ã‚¡ã‚¤ãƒ«ãŒå…±æœ‰ã•ã‚Œã¦ã„ãªã„")
                                st.write("- å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„ã€ã¾ãŸã¯å½¢å¼ãŒéå¯¾å¿œ")
                                st.write("- ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ãŒä¸è¶³ã—ã¦ã„ã‚‹")
                                
                        except Exception as api_error:
                            st.error(f"âŒ Google Drive APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {api_error}")
                            st.write(f"ğŸ” ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—: {type(api_error).__name__}")
                        
                    else:
                        st.error("âŒ Google Drive APIã‚µãƒ¼ãƒ“ã‚¹ã®åˆæœŸåŒ–ã«å¤±æ•—")
                        st.info("ğŸ’¡ Service Accountèªè¨¼æƒ…å ±ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
                        
                except ImportError as e:
                    st.error(f"âŒ GoogleDriveProcessor ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
                except Exception as e:
                    st.error(f"âŒ GoogleDriveProcessor åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
                    st.write(f"ğŸ” ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—: {type(e).__name__}")
                    st.write(f"ğŸ” ã‚¨ãƒ©ãƒ¼è©³ç´°: {str(e)}")
                    
            else:
                st.error("âŒ GOOGLE_DRIVE_CREDENTIALSãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
                st.info("ğŸ’¡ Streamlit Secretsã§èªè¨¼æƒ…å ±ã‚’è¨­å®šã—ã¦ãã ã•ã„")
                
            st.info("ğŸ” === Google Driveæœ€é©åŒ–è¨ºæ–­çµ‚äº† ===")
                    
        except Exception as e:
            st.error(f"âŒ Google Driveå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        
        # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        gc.collect()
        
        # 3. Discordå‡¦ç†ï¼ˆã‚¹ã‚­ãƒƒãƒ—ï¼‰
        status_text.text("ğŸ’¬ Discordå‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ä¸­...")
        progress_bar.progress(70)
        st.info("ğŸ’¬ Discordçµ±åˆ: ä¸€æ—¦ã‚¹ã‚­ãƒƒãƒ—ï¼ˆä»Šå¾Œå®Ÿè£…äºˆå®šï¼‰")
        
        # 4. æœ€é©åŒ–ãƒ™ã‚¯ãƒˆãƒ«DBçµ±åˆ
        status_text.text("ğŸ”„ æœ€é©åŒ–ãƒ™ã‚¯ãƒˆãƒ«çµ±åˆä¸­...")
        progress_bar.progress(90)
        
        st.info(f"ğŸ”„ æœ€é©åŒ–çµ±åˆå‡¦ç†: åˆè¨ˆ{len(documents)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ä¸­...")
        
        if documents:
            from vector_db_processor import VectorDBProcessor
            vector_db = VectorDBProcessor()
            
            if vector_db.collection:
                # ãƒãƒƒãƒå‡¦ç†ã§è² è·è»½æ¸›
                batch_size = 10
                total_batches = (len(documents) + batch_size - 1) // batch_size
                
                st.info(f"ğŸ”„ {len(documents)}ä»¶ã‚’{batch_size}ä»¶ãšã¤{total_batches}ãƒãƒƒãƒã§å‡¦ç†ä¸­...")
                
                # çµ±åˆå‰ã®ã‚«ã‚¦ãƒ³ãƒˆ
                before_count = vector_db.collection.count()
                st.info(f"ğŸ“Š çµ±åˆå‰ã®DBä»¶æ•°: {before_count}ä»¶")
                
                for i in range(0, len(documents), batch_size):
                    batch = documents[i:i + batch_size]
                    
                    try:
                        vector_db.add_documents(batch)
                        
                        # é€²æ—è¡¨ç¤º
                        batch_num = i // batch_size + 1
                        st.info(f"ğŸ“Š ãƒãƒƒãƒ{batch_num}/{total_batches}å®Œäº† ({len(batch)}ä»¶å‡¦ç†)")
                        
                        # 3ãƒãƒƒãƒã”ã¨ã«ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                        if batch_num % 3 == 0:
                            gc.collect()
                            time.sleep(0.1)  # è² è·è»½æ¸›
                        
                    except Exception as batch_error:
                        st.warning(f"âš ï¸ ãƒãƒƒãƒ{batch_num}å‡¦ç†ã‚¨ãƒ©ãƒ¼: {batch_error}")
                        continue
                
                # æœ€çµ‚ç¢ºèª
                after_count = vector_db.collection.count()
                added_count = after_count - before_count
                elapsed_time = time.time() - start_time
                
                progress_bar.progress(100)
                status_text.text("âœ… æœ€é©åŒ–çµ±åˆå®Œäº†!")
                
                st.success("ğŸ‰ æœ€é©åŒ–ãƒ‡ãƒ¼ã‚¿çµ±åˆå®Œäº†!")
                st.success(f"ğŸ“Š æ–°è¦è¿½åŠ : {added_count}ä»¶")
                st.success(f"ğŸ“Š ç·DBä»¶æ•°: {after_count}ä»¶")
                st.success(f"â° å‡¦ç†æ™‚é–“: {elapsed_time:.1f}ç§’")
                
                # æœ€é©åŒ–çµæœè©³ç´°
                display_optimization_results(documents, elapsed_time)
                
                return True
            else:
                st.error("âŒ ãƒ™ã‚¯ãƒˆãƒ«DBãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
                return False
        else:
            progress_bar.progress(100)
            status_text.text("âŒ çµ±åˆãƒ‡ãƒ¼ã‚¿ãªã—")
            
            st.warning("âš ï¸ çµ±åˆã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            st.error("âŒ å…¨ã¦ã®ã‚µãƒ¼ãƒ“ã‚¹ã§ãƒ‡ãƒ¼ã‚¿ãŒ0ä»¶ã§ã—ãŸ")
            
            # è¨ºæ–­æƒ…å ±
            with st.expander("ğŸ” è¨ºæ–­æƒ…å ±"):
                st.write("**è€ƒãˆã‚‰ã‚Œã‚‹åŸå› :**")
                st.write("1. **Notion**: ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ã€ãƒšãƒ¼ã‚¸ãŒå­˜åœ¨ã—ãªã„")
                st.write("2. **Google Drive**: Service Accountæœªå…±æœ‰ã€ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„")
                st.write("3. **èªè¨¼**: APIèªè¨¼æƒ…å ±ã®å•é¡Œ")
                
                st.write("**å¯¾ç­–:**")
                st.write("1. å„ã‚µãƒ¼ãƒ“ã‚¹ã®å€‹åˆ¥ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ")
                st.write("2. èªè¨¼æƒ…å ±ã®å†ç¢ºèª")
                st.write("3. ãƒ•ã‚¡ã‚¤ãƒ«å…±æœ‰è¨­å®šã®ç¢ºèª")
            
            return False
            
    except Exception as e:
        elapsed_time = time.time() - start_time
        st.error(f"âŒ æœ€é©åŒ–çµ±åˆã‚¨ãƒ©ãƒ¼: {e}")
        
        # ã‚¨ãƒ©ãƒ¼åˆ†æ
        with st.expander("ğŸ” ã‚¨ãƒ©ãƒ¼åˆ†æ"):
            st.write(f"**å®Ÿè¡Œæ™‚é–“**: {elapsed_time:.1f}ç§’")
            st.write(f"**å‡¦ç†æ¸ˆã¿ä»¶æ•°**: {len(documents) if 'documents' in locals() else 0}ä»¶")
            st.write(f"**ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—**: {type(e).__name__}")
            
            if elapsed_time > 300:  # 5åˆ†è¶…é
                st.warning("â° ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
                st.info("ğŸ’¡ ãƒ‡ãƒ¼ã‚¿é‡ã‚’å‰Šæ¸›ã™ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™")
            
            import traceback
            st.code(traceback.format_exc())
        
        return False

def display_optimization_results(documents, elapsed_time):
    """æœ€é©åŒ–çµæœè¡¨ç¤º"""
    
    with st.expander("ğŸ“Š æœ€é©åŒ–çµ±åˆçµæœè©³ç´°"):
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("ç·æ–‡æ›¸æ•°", len(documents))
            st.metric("å‡¦ç†æ™‚é–“", f"{elapsed_time:.1f}ç§’")
        
        with col2:
            # ã‚½ãƒ¼ã‚¹åˆ¥çµ±è¨ˆ
            sources = {}
            types = {}
            
            for doc in documents:
                source = doc.get('source', 'ä¸æ˜')
                doc_type = doc.get('type', 'ä¸æ˜')
                
                sources[source] = sources.get(source, 0) + 1
                types[doc_type] = types.get(doc_type, 0) + 1
            
            st.write("**ã‚½ãƒ¼ã‚¹åˆ¥:**")
            for source, count in sources.items():
                st.write(f"- {source}: {count}ä»¶")
            
            st.write("**ã‚¿ã‚¤ãƒ—åˆ¥:**")
            for doc_type, count in types.items():
                st.write(f"- {doc_type}: {count}ä»¶")
        
        with col3:
            # å“è³ªæŒ‡æ¨™
            total_chars = sum(len(doc.get('content', '')) for doc in documents)
            avg_chars = total_chars / len(documents) if documents else 0
            
            st.metric("ç·æ–‡å­—æ•°", f"{total_chars:,}")
            st.metric("å¹³å‡æ–‡å­—æ•°", f"{avg_chars:.0f}")
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡
        st.write("**ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡:**")
        if elapsed_time < 180:  # 3åˆ†ä»¥å†…
            st.success("ğŸš€ é«˜é€Ÿå‡¦ç†å®Œäº† - å„ªç§€")
        elif elapsed_time < 300:  # 5åˆ†ä»¥å†…
            st.info("âš¡ æ¨™æº–å‡¦ç†å®Œäº† - è‰¯å¥½")
        else:
            st.warning("ğŸŒ å‡¦ç†æ™‚é–“é•·ã‚ - è¦æœ€é©åŒ–")
        
        # å®Ÿç”¨æ€§æŒ‡æ¨™
        if len(documents) >= 200:
            st.success("ğŸ“Š ååˆ†ãªãƒ‡ãƒ¼ã‚¿é‡ - é«˜ã„å®Ÿç”¨æ€§")
        elif len(documents) >= 100:
            st.info("ğŸ“Š é©åº¦ãªãƒ‡ãƒ¼ã‚¿é‡ - å®Ÿç”¨çš„")
        else:
            st.warning("ğŸ“Š ãƒ‡ãƒ¼ã‚¿é‡å°‘ãªã‚ - åŸºæœ¬çš„å®Ÿç”¨æ€§")
        
        # æ¨å¥¨äº‹é …
        st.write("**æ¨å¥¨äº‹é …:**")
        st.write(f"- **ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿é‡**: {len(documents)}ä»¶ã¯æœ€é©ãƒãƒ©ãƒ³ã‚¹")
        st.write(f"- **å‡¦ç†æ™‚é–“**: {elapsed_time:.1f}ç§’ã§åŠ¹ç‡çš„")
        st.write(f"- **ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡**: ç´„{len(documents)*2}MB (æ¨å®š)")

def safe_integration():
    """ä¸‹ä½äº’æ›æ€§ã®ãŸã‚ã®é–¢æ•°"""
    return run_data_integration()

if __name__ == "__main__":
    safe_integration()

