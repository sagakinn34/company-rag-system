import sys
import os
import streamlit as st
import gc
import time

# çµ¶å¯¾ãƒ‘ã‚¹ã§srcãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¿½åŠ 
current_dir = os.path.dirname(os.path.abspath(__file__))
src_path = os.path.join(current_dir, '..', 'src') if 'src' not in current_dir else current_dir
sys.path.insert(0, src_path)

def run_data_integration():
    """æœ€é©åŒ–ç‰ˆãƒ‡ãƒ¼ã‚¿çµ±åˆï¼ˆæ—¢å­˜é–¢æ•°ã®æ”¹è‰¯ï¼‰"""
    
    # çµ±åˆé–‹å§‹è¡¨ç¤º
    st.info("âš–ï¸ æœ€é©åŒ–ãƒ‡ãƒ¼ã‚¿çµ±åˆã‚’é–‹å§‹...")
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–
    start_time = time.time()
    
    try:
        documents = []
        
        # === æœ€é©åŒ–è¨­å®š ===
        NOTION_OPTIMIZED = 150    # 300 â†’ 150 (50%å‰Šæ¸›)
        GDRIVE_OPTIMIZED = 100    # 200 â†’ 100 (50%å‰Šæ¸›)
        CONTENT_MAX_CHARS = 2000  # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æ–‡å­—æ•°åˆ¶é™
        
        # 1. Notionæœ€é©åŒ–å‡¦ç†
        status_text.text("ğŸ“ Notionæœ€é©åŒ–å–å¾—ä¸­...")
        progress_bar.progress(20)
        
        try:
            notion_token = st.secrets.get("NOTION_TOKEN")
            if notion_token:
                st.info("ğŸ“ NOTION_TOKEN: âœ… è¨­å®šæ¸ˆã¿")
                
                from notion_processor import NotionProcessor
                st.success("ğŸ“ NotionProcessor ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
                
                notion = NotionProcessor()
                st.success("ğŸ“ NotionProcessor ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆæˆåŠŸ")
                
                # æœ€é©åŒ–å–å¾—å®Ÿè¡Œ
                notion_docs = get_notion_optimized_data(notion, NOTION_OPTIMIZED, CONTENT_MAX_CHARS)
                st.info(f"ğŸ“ Notionæœ€é©åŒ–å–å¾—çµæœ: {len(notion_docs) if notion_docs else 0}ä»¶")
                
                if notion_docs:
                    documents.extend(notion_docs)
                    st.success(f"âœ… Notionæœ€é©åŒ–å–å¾—æˆåŠŸ: {len(notion_docs)}ä»¶")
                else:
                    st.warning("âš ï¸ Notionãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
            else:
                st.error("âŒ NOTION_TOKENãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
                
        except Exception as e:
            st.error(f"âŒ Notionå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        
        # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        gc.collect()
        
        # 2. Google Driveæœ€é©åŒ–å‡¦ç†
        status_text.text("ğŸ“‚ Google Driveæœ€é©åŒ–å–å¾—ä¸­...")
        progress_bar.progress(50)
        
        try:
            gdrive_creds = st.secrets.get("GOOGLE_DRIVE_CREDENTIALS")
            
            if gdrive_creds:
                st.success("ğŸ“‚ GOOGLE_DRIVE_CREDENTIALS: âœ… è¨­å®šæ¸ˆã¿")
                
                from gdrive_processor import GoogleDriveProcessor
                st.success("ğŸ“‚ GoogleDriveProcessor ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
                
                gdrive = GoogleDriveProcessor()
                st.success("ğŸ“‚ GoogleDriveProcessor ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆæˆåŠŸ")
                
                if gdrive.service:
                    st.success("âœ… Google Drive APIã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–æˆåŠŸ")
                    
                    # æœ€é©åŒ–å–å¾—å®Ÿè¡Œ
                    gdrive_docs = get_gdrive_optimized_data(gdrive, GDRIVE_OPTIMIZED, CONTENT_MAX_CHARS)
                    st.info(f"ğŸ“‚ Google Driveæœ€é©åŒ–å–å¾—çµæœ: {len(gdrive_docs) if gdrive_docs else 0}ä»¶")
                    
                    if gdrive_docs:
                        documents.extend(gdrive_docs)
                        st.success(f"âœ… Google Driveæœ€é©åŒ–å–å¾—æˆåŠŸ: {len(gdrive_docs)}ä»¶")
                    else:
                        st.warning("âš ï¸ Google Driveãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
                else:
                    st.error("âŒ Google Drive APIã‚µãƒ¼ãƒ“ã‚¹ã®åˆæœŸåŒ–ã«å¤±æ•—")
            else:
                st.error("âŒ GOOGLE_DRIVE_CREDENTIALSãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
                
        except Exception as e:
            st.error(f"âŒ Google Driveå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        
        # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        gc.collect()
        
        # 3. Discordå‡¦ç†ï¼ˆã‚¹ã‚­ãƒƒãƒ—ï¼‰
        status_text.text("ğŸ’¬ Discordå‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ä¸­...")
        progress_bar.progress(70)
        st.info("ğŸ’¬ Discordçµ±åˆ: ä¸€æ—¦ã‚¹ã‚­ãƒƒãƒ—ï¼ˆä»Šå¾Œå®Ÿè£…äºˆå®šï¼‰")
        
        # 4. æœ€é©åŒ–ãƒ™ã‚¯ãƒˆãƒ«DBçµ±åˆ
        status_text.text("ğŸ”„ æœ€é©åŒ–ãƒ™ã‚¯ãƒˆãƒ«çµ±åˆä¸­...")
        progress_bar.progress(90)
        
        st.info(f"ğŸ”„ æœ€é©åŒ–çµ±åˆå‡¦ç†: åˆè¨ˆ{len(documents)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ä¸­...")
        
        if documents:
            from vector_db_processor import VectorDBProcessor
            vector_db = VectorDBProcessor()
            
            if vector_db.collection:
                # ãƒãƒƒãƒå‡¦ç†ã§è² è·è»½æ¸›
                batch_size = 10
                total_batches = (len(documents) + batch_size - 1) // batch_size
                
                st.info(f"ğŸ”„ {len(documents)}ä»¶ã‚’{batch_size}ä»¶ãšã¤{total_batches}ãƒãƒƒãƒã§å‡¦ç†ä¸­...")
                
                for i in range(0, len(documents), batch_size):
                    batch = documents[i:i + batch_size]
                    
                    try:
                        vector_db.add_documents(batch)
                        
                        # é€²æ—è¡¨ç¤º
                        batch_num = i // batch_size + 1
                        st.info(f"ğŸ“Š ãƒãƒƒãƒ{batch_num}/{total_batches}å®Œäº† ({len(batch)}ä»¶å‡¦ç†)")
                        
                        # 3ãƒãƒƒãƒã”ã¨ã«ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                        if batch_num % 3 == 0:
                            gc.collect()
                            time.sleep(0.1)  # è² è·è»½æ¸›
                        
                    except Exception as batch_error:
                        st.warning(f"âš ï¸ ãƒãƒƒãƒ{batch_num}å‡¦ç†ã‚¨ãƒ©ãƒ¼: {batch_error}")
                        continue
                
                # æœ€çµ‚ç¢ºèª
                final_count = vector_db.collection.count()
                elapsed_time = time.time() - start_time
                
                progress_bar.progress(100)
                status_text.text("âœ… æœ€é©åŒ–çµ±åˆå®Œäº†!")
                
                st.success(f"ğŸ‰ æœ€é©åŒ–ãƒ‡ãƒ¼ã‚¿çµ±åˆå®Œäº†!")
                st.success(f"ğŸ“Š ç·DBä»¶æ•°: {final_count}ä»¶")
                st.success(f"â° å‡¦ç†æ™‚é–“: {elapsed_time:.1f}ç§’")
                
                # æœ€é©åŒ–çµæœè©³ç´°
                display_optimization_results(documents, elapsed_time)
                
                return True
            else:
                st.error("âŒ ãƒ™ã‚¯ãƒˆãƒ«DBãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
                return False
        else:
            progress_bar.progress(100)
            status_text.text("âŒ çµ±åˆãƒ‡ãƒ¼ã‚¿ãªã—")
            
            st.warning("âš ï¸ çµ±åˆã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return False
            
    except Exception as e:
        elapsed_time = time.time() - start_time
        st.error(f"âŒ æœ€é©åŒ–çµ±åˆã‚¨ãƒ©ãƒ¼: {e}")
        
        # ã‚¨ãƒ©ãƒ¼åˆ†æ
        with st.expander("ğŸ” ã‚¨ãƒ©ãƒ¼åˆ†æ"):
            st.write(f"**å®Ÿè¡Œæ™‚é–“**: {elapsed_time:.1f}ç§’")
            st.write(f"**å‡¦ç†æ¸ˆã¿ä»¶æ•°**: {len(documents) if 'documents' in locals() else 0}ä»¶")
            
            if elapsed_time > 300:  # 5åˆ†è¶…é
                st.warning("â° ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
        
        return False

def get_notion_optimized_data(notion, limit: int, max_chars: int):
    """Notionæœ€é©åŒ–ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆæ—¢å­˜å‡¦ç†ã®æ”¹è‰¯ï¼‰"""
    try:
        documents = []
        processed_count = 0
        
        # æœ€æ–°ãƒšãƒ¼ã‚¸å„ªå…ˆå–å¾—
        results = notion.client.search(
            **{
                "page_size": min(limit, 100),
                "sort": {
                    "direction": "descending",
                    "timestamp": "last_edited_time"
                }
            }
        )
        
        for item in results.get('results', []):
            if processed_count >= limit:
                break
                
            try:
                # ãƒšãƒ¼ã‚¸ã¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’åŒºåˆ¥
                if item.get('object') == 'page':
                    content = extract_page_content_optimized(notion, item['id'], max_chars)
                elif item.get('object') == 'database':
                    content = extract_database_content_optimized(notion, item['id'], max_chars)
                else:
                    continue
                
                if content and len(content.strip()) > 20:  # æœ€å°æ–‡å­—æ•°ãƒã‚§ãƒƒã‚¯
                    document = {
                        'id': f"notion_{item['id']}",
                        'title': get_title_safe(item),
                        'content': content[:max_chars],  # æ–‡å­—æ•°åˆ¶é™
                        'source': 'notion',
                        'type': item.get('object', 'unknown'),
                        'url': item.get('url', ''),
                        'last_edited': item.get('last_edited_time', '')
                    }
                    documents.append(document)
                    processed_count += 1
                    
                    if processed_count % 10 == 0:  # 10ä»¶ã”ã¨ã«é€²æ—è¡¨ç¤º
                        st.info(f"ğŸ“„ Notionå‡¦ç†ä¸­: {processed_count}/{limit}ä»¶")
                
            except Exception as e:
                print(f"âš ï¸ Notionã‚¢ã‚¤ãƒ†ãƒ å‡¦ç†ã‚¹ã‚­ãƒƒãƒ—: {e}")
                continue
        
        return documents
        
    except Exception as e:
        st.error(f"âŒ Notionæœ€é©åŒ–å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return []

def get_gdrive_optimized_data(gdrive, limit: int, max_chars: int):
    """Google Driveæœ€é©åŒ–ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆæ—¢å­˜å‡¦ç†ã®æ”¹è‰¯ï¼‰"""
    try:
        documents = []
        
        # åŠ¹ç‡çš„ãªå–å¾—æˆ¦ç•¥ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—åˆ¥ï¼‰
        strategies = [
            {
                'name': 'Google Docs',
                'query': "trashed=false and mimeType='application/vnd.google-apps.document'",
                'limit': int(limit * 0.6)  # 60%
            },
            {
                'name': 'PDF',
                'query': "trashed=false and mimeType='application/pdf'",
                'limit': int(limit * 0.25)  # 25%
            },
            {
                'name': 'ãã®ä»–',
                'query': "trashed=false and (mimeType contains 'spreadsheet' or mimeType contains 'presentation')",
                'limit': int(limit * 0.15)  # 15%
            }
        ]
        
        for strategy in strategies:
            try:
                st.info(f"ğŸ“‚ {strategy['name']}å–å¾—ä¸­... (ä¸Šé™: {strategy['limit']}ä»¶)")
                
                results = gdrive.service.files().list(
                    q=strategy['query'],
                    pageSize=strategy['limit'],
                    orderBy='modifiedTime desc',
                    fields="files(id, name, mimeType, size, createdTime, modifiedTime)"
                ).execute()
                
                files = results.get('files', [])
                
                for file_info in files:
                    if len(documents) >= limit:
                        break
                    
                    try:
                        # è»½é‡ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
                        text_content = extract_text_optimized(gdrive, file_info, max_chars)
                        
                        if text_content and len(text_content.strip()) > 10:
                            document = {
                                'id': f"gdrive_{file_info['id']}",
                                'title': file_info['name'],
                                'content': text_content[:max_chars],  # æ–‡å­—æ•°åˆ¶é™
                                'source': 'google_drive',
                                'type': 'file',
                                'mime_type': file_info['mimeType'],
                                'url': f"https://drive.google.com/file/d/{file_info['id']}/view"
                            }
                            documents.append(document)
                            
                    except Exception as file_error:
                        print(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¹ã‚­ãƒƒãƒ—: {file_error}")
                        continue
                
                st.success(f"âœ… {strategy['name']}: {len([d for d in documents if strategy['name'].lower() in d.get('mime_type', '').lower()])}ä»¶å–å¾—")
                
            except Exception as strategy_error:
                st.warning(f"âš ï¸ {strategy['name']}å–å¾—ã‚¨ãƒ©ãƒ¼: {strategy_error}")
                continue
        
        return documents
        
    except Exception as e:
        st.error(f"âŒ Google Driveæœ€é©åŒ–å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return []

# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
def extract_page_content_optimized(notion, page_id: str, max_chars: int) -> str:
    """æœ€é©åŒ–ãƒšãƒ¼ã‚¸ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æŠ½å‡º"""
    try:
        # ç°¡æ˜“ç‰ˆï¼šãƒ–ãƒ­ãƒƒã‚¯å–å¾—ã‚’åˆ¶é™
        blocks_response = notion.client.blocks.children.list(
            block_id=page_id,
            page_size=20  # ãƒ–ãƒ­ãƒƒã‚¯æ•°åˆ¶é™
        )
        blocks = blocks_response.get('results', [])
        
        content_parts = []
        total_chars = 0
        
        for block in blocks:
            if total_chars >= max_chars:
                break
                
            block_text = extract_block_text_simple(block)
            if block_text and len(block_text.strip()) > 0:
                content_parts.append(block_text)
                total_chars += len(block_text)
        
        return '\n\n'.join(content_parts)[:max_chars]
        
    except Exception as e:
        return f"ãƒšãƒ¼ã‚¸å†…å®¹å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}"

def extract_text_optimized(gdrive, file_info: dict, max_chars: int) -> str:
    """æœ€é©åŒ–ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º"""
    try:
        mime_type = file_info['mimeType']
        file_id = file_info['id']
        
        if mime_type == 'application/vnd.google-apps.document':
            request = gdrive.service.files().export_media(fileId=file_id, mimeType='text/plain')
            content = request.execute().decode('utf-8', errors='ignore')
            return content[:max_chars]
        else:
            # ãã®ä»–ã¯ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ã¿
            return f"ãƒ•ã‚¡ã‚¤ãƒ«: {file_info['name']}\nã‚¿ã‚¤ãƒ—: {mime_type}"
            
    except Exception as e:
        return f"ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {str(e)}"

def display_optimization_results(documents, elapsed_time):
    """æœ€é©åŒ–çµæœè¡¨ç¤º"""
    with st.expander("ğŸ“Š æœ€é©åŒ–çµæœè©³ç´°"):
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("ç·æ–‡æ›¸æ•°", len(documents))
            st.metric("å‡¦ç†æ™‚é–“", f"{elapsed_time:.1f}ç§’")
        
        with col2:
            sources = {}
            for doc in documents:
                source = doc.get('source', 'ä¸æ˜')
                sources[source] = sources.get(source, 0) + 1
            
            st.write("**ã‚½ãƒ¼ã‚¹åˆ¥:**")
            for source, count in sources.items():
                st.write(f"- {source}: {count}ä»¶")
        
        with col3:
            total_chars = sum(len(doc.get('content', '')) for doc in documents)
            avg_chars = total_chars / len(documents) if documents else 0
            
            st.metric("ç·æ–‡å­—æ•°", f"{total_chars:,}")
            st.metric("å¹³å‡æ–‡å­—æ•°", f"{avg_chars:.0f}")
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡
        if elapsed_time < 180:  # 3åˆ†ä»¥å†…
            st.success("ğŸš€ é«˜é€Ÿå‡¦ç†å®Œäº†")
        elif elapsed_time < 300:  # 5åˆ†ä»¥å†…
            st.info("âš¡ æ¨™æº–å‡¦ç†å®Œäº†")
        else:
            st.warning("ğŸŒ å‡¦ç†æ™‚é–“é•·ã‚")

# æ—¢å­˜é–¢æ•°ï¼ˆä¸‹ä½äº’æ›ï¼‰
def safe_integration():
    """ä¸‹ä½äº’æ›æ€§ã®ãŸã‚ã®é–¢æ•°"""
    return run_data_integration()

if __name__ == "__main__":
    safe_integration()
