import os
import sys

# Streamlit Cloudç’°å¢ƒã§ã®SQLite3å•é¡Œã‚’å¼·åˆ¶çš„ã«è§£æ±º
def fix_sqlite3():
    """SQLite3ãƒãƒ¼ã‚¸ãƒ§ãƒ³å•é¡Œã‚’å¼·åˆ¶çš„ã«ä¿®æ­£"""
    try:
        import pysqlite3
        sys.modules['sqlite3'] = pysqlite3
        print("âœ… pysqlite3ã‚’å¼·åˆ¶é©ç”¨ã—ã¾ã—ãŸ")
    except ImportError:
        print("âš ï¸ pysqlite3ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ - æ¨™æº–sqlite3ã‚’ä½¿ç”¨")

# ChromaDBã‚¤ãƒ³ãƒãƒ¼ãƒˆå‰ã«SQLite3ã‚’ä¿®æ­£
fix_sqlite3()

import chromadb
from typing import List, Dict, Any
import json
import numpy as np

def create_sentence_transformer():
    """åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚’å®‰å…¨ã«ä½œæˆï¼ˆå…¨ãƒãƒ¼ã‚¸ãƒ§ãƒ³å¯¾å¿œï¼‰"""
    try:
        from sentence_transformers import SentenceTransformer
        import torch
        
        print("åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­...")
        
        # ãƒ‡ãƒã‚¤ã‚¹è¨­å®š
        device = 'cpu'  # Streamlit Cloudã§ã¯å®‰å…¨ã«CPUã‚’ä½¿ç”¨
        
        # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ï¼ˆãƒãƒ¼ã‚¸ãƒ§ãƒ³äº’æ›æ€§è€ƒæ…®ï¼‰
        try:
            # æœ€æ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç”¨ã®åˆæœŸåŒ–
            model = SentenceTransformer(
                'intfloat/multilingual-e5-small',
                device=device,
                trust_remote_code=False,
                cache_folder=None
            )
        except Exception as e1:
            print(f"âš ï¸ æ–°å½¢å¼ã§ã®åˆæœŸåŒ–å¤±æ•—: {e1}")
            try:
                # å¾“æ¥å½¢å¼ã§ã®åˆæœŸåŒ–
                model = SentenceTransformer('intfloat/multilingual-e5-small')
                model = model.to(device)
            except Exception as e2:
                print(f"âš ï¸ å¾“æ¥å½¢å¼ã§ã‚‚å¤±æ•—: {e2}")
                # ã‚ˆã‚Šè»½é‡ãªãƒ¢ãƒ‡ãƒ«ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                print("ðŸ”„ è»½é‡ãƒ¢ãƒ‡ãƒ«ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯...")
                model = SentenceTransformer('all-MiniLM-L6-v2')
                model = model.to(device)
        
        print("âœ… ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")
        return model
        
    except ImportError as e:
        print(f"âŒ SentenceTransformersã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        return None
    except Exception as e:
        print(f"âŒ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return None

class VectorDBProcessor:
    def __init__(self, db_path: str = "./chroma_db"):
        self.db_path = db_path
        self.client = None
        self.collection = None
        self.model = None
        
        # ChromaDBåˆæœŸåŒ–
        self._init_chromadb()
        
        # åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
        if self.collection:
            self.model = create_sentence_transformer()
    
    def _init_chromadb(self):
        """ChromaDBã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–"""
        try:
            print("ChromaDBã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–ä¸­...")
            self.client = chromadb.PersistentClient(path=self.db_path)
            self.collection = self.client.get_or_create_collection(
                name="company_docs",
                metadata={"hnsw:space": "cosine"}
            )
            print("âœ… ChromaDBã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âŒ ChromaDBæ°¸ç¶šåŒ–åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            try:
                print("ðŸ”„ ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªãƒ¢ãƒ¼ãƒ‰ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä¸­...")
                self.client = chromadb.Client()
                self.collection = self.client.get_or_create_collection(
                    name="company_docs",
                    metadata={"hnsw:space": "cosine"}
                )
                print("âœ… ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªãƒ¢ãƒ¼ãƒ‰åˆæœŸåŒ–æˆåŠŸ")
            except Exception as e2:
                print(f"âŒ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¤±æ•—: {e2}")
                self.client = None
                self.collection = None
    
    def add_documents(self, documents: List[Dict[str, Any]]):
        """æ–‡æ›¸ã‚’ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«è¿½åŠ """
        if not self.collection:
            print("âŒ ChromaDBãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return
        
        if not self.model:
            print("âŒ åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            return
        
        try:
            texts = []
            metadatas = []
            ids = []
            
            for i, doc in enumerate(documents):
                content = str(doc.get('content', ''))[:8000]  # é•·ã™ãŽã‚‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’åˆ¶é™
                texts.append(content)
                metadatas.append({
                    'source': str(doc.get('source', '')),
                    'title': str(doc.get('title', '')),
                    'type': str(doc.get('type', ''))
                })
                ids.append(f"doc_{i}_{abs(hash(content))}")
            
            print(f"ðŸ“ {len(texts)}ä»¶ã®æ–‡æ›¸ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ä¸­...")
            
            # ãƒãƒƒãƒå‡¦ç†ã§ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’åˆ¶é™
            batch_size = 16
            all_embeddings = []
            
            for i in range(0, len(texts), batch_size):
                batch_texts = texts[i:i + batch_size]
                try:
                    # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å®Ÿè¡Œ
                    batch_embeddings = self.model.encode(
                        batch_texts,
                        show_progress_bar=False,
                        convert_to_numpy=True,
                        normalize_embeddings=True
                    )
                    
                    # numpyé…åˆ—ã‚’ãƒªã‚¹ãƒˆã«å¤‰æ›
                    if isinstance(batch_embeddings, np.ndarray):
                        batch_embeddings = batch_embeddings.tolist()
                    
                    all_embeddings.extend(batch_embeddings)
                    print(f"âœ… ãƒãƒƒãƒ {i//batch_size + 1} å®Œäº†")
                    
                except Exception as e:
                    print(f"âŒ ãƒãƒƒãƒå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                    # ãƒ€ãƒŸãƒ¼ãƒ™ã‚¯ãƒˆãƒ«ã§ä»£æ›¿
                    dummy_dim = 384  # ä¸€èˆ¬çš„ãªæ¬¡å…ƒæ•°
                    dummy_vectors = [[0.0] * dummy_dim] * len(batch_texts)
                    all_embeddings.extend(dummy_vectors)
            
            # ChromaDBã«è¿½åŠ 
            self.collection.add(
                embeddings=all_embeddings,
                documents=texts,
                metadatas=metadatas,
                ids=ids
            )
            
            print(f"âœ… {len(documents)}ä»¶ã®æ–‡æ›¸ã‚’ChromaDBã«è¿½åŠ ã—ã¾ã—ãŸ")
            
        except Exception as e:
            print(f"âŒ æ–‡æ›¸è¿½åŠ ã‚¨ãƒ©ãƒ¼: {e}")
    
    def search(self, query: str, n_results: int = 20) -> List[Dict]:
        """ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢å®Ÿè¡Œ"""
        if not self.collection:
            print("âŒ ChromaDBãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return []
        
        try:
            max_results = min(n_results, 50)
            
            if self.model:
                # ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢
                query_embedding = self.model.encode([query], normalize_embeddings=True)[0]
                if isinstance(query_embedding, np.ndarray):
                    query_embedding = query_embedding.tolist()
                
                results = self.collection.query(
                    query_embeddings=[query_embedding],
                    n_results=max_results,
                    include=['metadatas', 'documents', 'distances']
                )
            else:
                # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                print("âš ï¸ åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«åˆ©ç”¨ä¸å¯ - ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã‚’å®Ÿè¡Œ")
                all_docs = self.collection.get()
                matched_docs = []
                
                query_lower = query.lower()
                for i, doc in enumerate(all_docs['documents']):
                    if query_lower in doc.lower():
                        matched_docs.append({
                            'content': doc,
                            'metadata': all_docs['metadatas'][i],
                            'distance': 0.5
                        })
                
                return matched_docs[:max_results]
            
            # çµæžœã‚’æ•´å½¢
            formatted_results = []
            if results['documents'] and len(results['documents']) > 0:
                for i in range(len(results['documents'][0])):
                    formatted_results.append({
                        'content': results['documents'][0][i],
                        'metadata': results['metadatas'][0][i],
                        'distance': results['distances'][0][i]
                    })
            
            return formatted_results
            
        except Exception as e:
            print(f"âŒ æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def get_stats(self):
        """çµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
        if not self.collection:
            return {"total_documents": 0, "status": "error: not initialized"}
        
        try:
            count = self.collection.count()
            return {
                "total_documents": count,
                "status": "success" if count > 0 else "empty"
            }
        except Exception as e:
            return {
                "total_documents": 0,
                "status": f"error: {e}"
            }

