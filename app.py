import streamlit as st
import sys
import os

# ãƒ‘ã‚¹è¨­å®š
sys.path.append('src')

st.set_page_config(
    page_title="ä¼æ¥­RAGã‚·ã‚¹ãƒ†ãƒ  v7.0",
    page_icon="ðŸ¢",
    layout="wide"
)

def check_system_requirements():
    """ã‚·ã‚¹ãƒ†ãƒ è¦ä»¶ãƒã‚§ãƒƒã‚¯"""
    st.sidebar.header("ðŸ”§ ã‚·ã‚¹ãƒ†ãƒ è¨ºæ–­")
    
    # SQLite3ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãƒã‚§ãƒƒã‚¯
    try:
        import sqlite3
        sqlite_version = sqlite3.sqlite_version
        st.sidebar.info(f"SQLite3ãƒãƒ¼ã‚¸ãƒ§ãƒ³: {sqlite_version}")
        
        # ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ¯”è¼ƒ
        version_parts = [int(x) for x in sqlite_version.split('.')]
        if version_parts >= [3, 35, 0]:
            st.sidebar.success("âœ… SQLite3ãƒãƒ¼ã‚¸ãƒ§ãƒ³: å¯¾å¿œæ¸ˆã¿")
        else:
            st.sidebar.warning("âš ï¸ SQLite3ãƒãƒ¼ã‚¸ãƒ§ãƒ³: è¦å¯¾å¿œ")
            
    except Exception as e:
        st.sidebar.error(f"âŒ SQLite3ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
    
    # ChromaDBãƒã‚§ãƒƒã‚¯
    try:
        from vector_db_processor import VectorDBProcessor
        vector_db = VectorDBProcessor()
        if vector_db.collection:
            stats = vector_db.get_stats()
            st.sidebar.success(f"âœ… ChromaDB: {stats['total_documents']}ä»¶")
            return vector_db
        else:
            st.sidebar.error("âŒ ChromaDB: åˆæœŸåŒ–å¤±æ•—")
            return None
    except Exception as e:
        st.sidebar.error(f"âŒ ChromaDBã‚¨ãƒ©ãƒ¼: {e}")
        return None

def main():
    st.title("ðŸ¢ ä¼æ¥­RAGã‚·ã‚¹ãƒ†ãƒ  v7.0 - æœ€é©åŒ–ç‰ˆ")
    
    # ã‚·ã‚¹ãƒ†ãƒ è¨ºæ–­
    vector_db = check_system_requirements()
    
    # ç’°å¢ƒå¤‰æ•°ãƒã‚§ãƒƒã‚¯
    with st.sidebar:
        st.header("ðŸ”‘ ç’°å¢ƒå¤‰æ•°")
        env_checks = {
            "NOTION_TOKEN": bool(st.secrets.get("NOTION_TOKEN")),
            "OPENAI_API_KEY": bool(st.secrets.get("OPENAI_API_KEY")),
            "DISCORD_TOKEN": bool(st.secrets.get("DISCORD_TOKEN")),
            "GOOGLE_DRIVE_CREDENTIALS": bool(st.secrets.get("GOOGLE_DRIVE_CREDENTIALS"))
        }
        
        for var_name, is_set in env_checks.items():
            if is_set:
                st.success(f"âœ… {var_name}")
            else:
                st.error(f"âŒ {var_name}")
        
        # ãƒ‡ãƒ¼ã‚¿çµ±åˆ
        st.header("ðŸ”„ ãƒ‡ãƒ¼ã‚¿çµ±åˆ")
        if st.button("ðŸš€ æœ€é©åŒ–çµ±åˆå®Ÿè¡Œ"):
            if vector_db and vector_db.collection:
                try:
                    from final_integration import run_data_integration
                    result = run_data_integration()
                    if result:
                        st.success("âœ… æœ€é©åŒ–çµ±åˆå®Œäº†")
                        st.rerun()
                    else:
                        st.warning("âš ï¸ ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                except Exception as e:
                    st.error(f"âŒ çµ±åˆã‚¨ãƒ©ãƒ¼: {e}")
            else:
                st.error("âŒ ChromaDBãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
    
    # ã‚·ã‚¹ãƒ†ãƒ ãŒæ­£å¸¸ã§ãªã„å ´åˆã®è­¦å‘Šè¡¨ç¤º
    if not vector_db or not vector_db.collection:
        st.error("ðŸš¨ ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼")
        st.markdown("""
        **ChromaDBã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚**
        
        è€ƒãˆã‚‰ã‚Œã‚‹åŽŸå› ï¼š
        - SQLite3ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®å•é¡Œ
        - ä¾å­˜é–¢ä¿‚ã®ç«¶åˆ
        - ãƒ¡ãƒ¢ãƒªä¸è¶³
        
        **å¯¾å‡¦æ–¹æ³•ï¼š**
        1. ãƒšãƒ¼ã‚¸ã‚’å†èª­ã¿è¾¼ã¿ã—ã¦ãã ã•ã„
        2. å•é¡ŒãŒç¶šãå ´åˆã¯ã€ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…ã«ãŠå•ã„åˆã‚ã›ãã ã•ã„
        """)
        return
    
    # æ­£å¸¸ãªå ´åˆã¯æœ¬æ¥ã®ã‚¿ãƒ–æ§‹æˆã‚’è¡¨ç¤º
    tab1, tab2, tab3, tab4 = st.tabs(["ðŸ  ãƒ›ãƒ¼ãƒ ", "ðŸ” é«˜åº¦æ¤œç´¢ãƒ»åˆ†æž", "ðŸ’¬ AIãƒãƒ£ãƒƒãƒˆ", "ðŸ““ Notionçµ±åˆ"])
    
    with tab1:
        st.header("ðŸ  ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦")
        st.markdown("""
        ### ðŸŽ¯ ä¼æ¥­RAGã‚·ã‚¹ãƒ†ãƒ  v7.0ã®æ©Ÿèƒ½ï¼ˆæœ€é©åŒ–ç‰ˆï¼‰
        
        **ðŸ” ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹çµ±åˆ:**
        - **Notion**: ãƒšãƒ¼ã‚¸ãƒ»ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼ˆ150ä»¶ä¸Šé™ï¼‰
        - **Google Drive**: PDFã€Wordã€Excelã€PowerPointï¼ˆ100ä»¶ä¸Šé™ï¼‰
        - **Discord**: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ï¼ˆä»Šå¾Œå®Ÿè£…ï¼‰
        
        **ðŸ¤– AIåˆ†æžæ©Ÿèƒ½:**
        - **OpenAI GPT-4o**: 128,000ãƒˆãƒ¼ã‚¯ãƒ³å¯¾å¿œ
        - **é«˜åº¦åˆ†æž**: åŒ…æ‹¬çš„è¦ç´„ãƒ»æ·±å±¤æ´žå¯Ÿãƒ»æˆ¦ç•¥çš„æŽ¨å¥¨
        - **ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢**: æ„å‘³çš„é¡žä¼¼æ€§ã«ã‚ˆã‚‹æ–‡æ›¸æ¤œç´¢
        
        **âš–ï¸ æœ€é©åŒ–ç‰¹å¾´:**
        - **å®Ÿç”¨æ€§**: ååˆ†ãªæƒ…å ±é‡ï¼ˆ250ä»¶ï¼‰
        - **å¯ç”¨æ€§**: å®‰å®šã—ãŸå‹•ä½œï¼ˆå‡¦ç†æ™‚é–“çŸ­ç¸®ï¼‰
        - **åŠ¹çŽ‡æ€§**: ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æœ€é©åŒ–
        
        **ðŸ“Š ç¾åœ¨ã®çŠ¶æ³:**
        """)
        
        # çµ±è¨ˆæƒ…å ±è¡¨ç¤º
        if vector_db:
            stats = vector_db.get_stats()
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("æ–‡æ›¸æ•°", stats['total_documents'])
            with col2:
                st.metric("ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", stats['status'])
            with col3:
                st.metric("ChromaDB", "âœ… æ­£å¸¸")
    
    with tab2:
        st.header("ðŸ” é«˜åº¦æ¤œç´¢ãƒ»åˆ†æžã‚·ã‚¹ãƒ†ãƒ ")
        
        # æ¤œç´¢ã‚¯ã‚¨ãƒªå…¥åŠ›
        search_query = st.text_input(
            "ðŸ” æ¤œç´¢ãƒ»åˆ†æžã‚¯ã‚¨ãƒªã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
            placeholder="ä¾‹: å–¶æ¥­æˆ¦ç•¥ã«ã¤ã„ã¦ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆé€²æ—ã«ã¤ã„ã¦ã€æŠ€è¡“çš„èª²é¡Œã«ã¤ã„ã¦"
        )
        
        # æ¤œç´¢ãƒ¢ãƒ¼ãƒ‰é¸æŠž
        search_mode = st.radio(
            "æ¤œç´¢ãƒ¢ãƒ¼ãƒ‰:",
            ["ðŸ” æ¨™æº–æ¤œç´¢", "ðŸ§  é«˜åº¦åˆ†æž"],
            horizontal=True
        )
        
        if search_mode == "ðŸ” æ¨™æº–æ¤œç´¢":
            # æ—¢å­˜ã®æ¨™æº–æ¤œç´¢
            max_results = st.slider("æœ€å¤§çµæžœæ•°", 1, 20, 5)
            
            if st.button("ðŸ” æ¤œç´¢å®Ÿè¡Œ") and search_query and vector_db:
                with st.spinner("æ¤œç´¢ä¸­..."):
                    results = vector_db.search(search_query, n_results=max_results)
                
                if results:
                    st.success(f"âœ… {len(results)}ä»¶ã®é–¢é€£æ–‡æ›¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
                    for i, result in enumerate(results):
                        with st.expander(f"ðŸ“„ çµæžœ {i+1}: {result['metadata'].get('title', 'ç„¡é¡Œ')}"):
                            st.write(f"**ã‚½ãƒ¼ã‚¹**: {result['metadata'].get('source', 'ä¸æ˜Ž')}")
                            st.write(f"**é¡žä¼¼åº¦**: {1-result['distance']:.3f}")
                            st.text(result['content'][:500] + "..." if len(result['content']) > 500 else result['content'])
                else:
                    st.warning("âš ï¸ é–¢é€£ã™ã‚‹æ–‡æ›¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        
        else:  # é«˜åº¦åˆ†æžãƒ¢ãƒ¼ãƒ‰
            # åˆ†æžè¨­å®š
            with st.expander("âš™ï¸ é«˜åº¦åˆ†æžè¨­å®š", expanded=True):
                col1, col2 = st.columns(2)
                
                with col1:
                    analysis_type = st.selectbox(
                        "ðŸ“Š åˆ†æžã‚¿ã‚¤ãƒ—:",
                        options=["summary", "insights", "recommendations"],
                        format_func=lambda x: {
                            "summary": "ðŸ“‹ åŒ…æ‹¬çš„è¦ç´„ï¼ˆè©³ç´°ç‰ˆï¼‰",
                            "insights": "ðŸ’¡ æ·±å±¤æ´žå¯Ÿï¼ˆå¤šè§’çš„åˆ†æžï¼‰",
                            "recommendations": "ðŸš€ æˆ¦ç•¥çš„æŽ¨å¥¨ï¼ˆå®Ÿè¡Œè¨ˆç”»ä»˜ãï¼‰"
                        }[x]
                    )
                
                with col2:
                    max_results = st.slider(
                        "ðŸ“š å‚ç…§ãƒ‡ãƒ¼ã‚¿æ•°",
                        min_value=10,
                        max_value=50,
                        value=20,
                        help="å¤šã„ã»ã©åŒ…æ‹¬çš„ã§ã™ãŒã€å‡¦ç†æ™‚é–“ãŒå¢—åŠ ã—ã¾ã™"
                    )
            
            # é«˜åº¦åˆ†æžå®Ÿè¡Œ
            if st.button("ðŸš€ é«˜åº¦åˆ†æžå®Ÿè¡Œ", type="primary") and search_query and vector_db:
                with st.spinner("ðŸ§  é«˜åº¦åˆ†æžå®Ÿè¡Œä¸­..."):
                    # ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢
                    results = vector_db.search(search_query, n_results=max_results)
                    
                    if results:
                        st.success(f"âœ… {len(results)}ä»¶ã®é–¢é€£ãƒ‡ãƒ¼ã‚¿ã‚’ç™ºè¦‹")
                        
                        # AIåˆ†æžå®Ÿè¡Œ
                        analysis_result = perform_ai_analysis(search_query, results, analysis_type)
                        
                        # çµæžœè¡¨ç¤º
                        st.markdown("---")
                        st.markdown(f"## ðŸŽ¯ ã€Œ{search_query}ã€ã®åˆ†æžçµæžœ")
                        st.markdown(analysis_result)
                        
                        # å‚ç…§ãƒ‡ãƒ¼ã‚¿è©³ç´°
                        display_reference_data(results)
                        
                    else:
                        st.warning("âš ï¸ é–¢é€£ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
    
    with tab3:
        st.header("ðŸ’¬ AIãƒãƒ£ãƒƒãƒˆï¼ˆRAGæ©Ÿèƒ½ä»˜ãï¼‰")
        
        if "messages" not in st.session_state:
            st.session_state.messages = []
        
        # ãƒãƒ£ãƒƒãƒˆå±¥æ­´è¡¨ç¤º
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
        if prompt := st.chat_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„..."):
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)
            
            # AIå¿œç­”ç”Ÿæˆ
            with st.chat_message("assistant"):
                if vector_db and st.secrets.get("OPENAI_API_KEY"):
                    try:
                        # é–¢é€£æ–‡æ›¸æ¤œç´¢
                        relevant_docs = vector_db.search(prompt, n_results=3)
                        
                        # OpenAI APIå‘¼ã³å‡ºã—
                        import openai
                        openai.api_key = st.secrets["OPENAI_API_KEY"]
                        
                        context = ""
                        if relevant_docs:
                            context = "\n\n".join([doc['content'][:300] for doc in relevant_docs])
                        
                        messages = [
                            {"role": "system", "content": f"""ã‚ãªãŸã¯ä¼æ¥­ã®æƒ…å ±ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®é–¢é€£æ–‡æ›¸ã‚’å‚è€ƒã«ã—ã¦è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚

é–¢é€£æ–‡æ›¸:
{context}

å›žç­”ã¯æ—¥æœ¬èªžã§ç°¡æ½”ã«ç­”ãˆã¦ãã ã•ã„ã€‚"""},
                            {"role": "user", "content": prompt}
                        ]
                        
                        response = openai.ChatCompletion.create(
                            model="gpt-4",
                            messages=messages,
                            max_tokens=1000,
                            temperature=0.7
                        )
                        
                        ai_response = response.choices[0].message.content
                        st.markdown(ai_response)
                        st.session_state.messages.append({"role": "assistant", "content": ai_response})
                        
                    except Exception as e:
                        error_msg = f"âŒ AIå¿œç­”ã‚¨ãƒ©ãƒ¼: {e}"
                        st.error(error_msg)
                        st.session_state.messages.append({"role": "assistant", "content": error_msg})
                else:
                    error_msg = "âŒ ChromaDBã¾ãŸã¯OpenAI APIãŒåˆ©ç”¨ã§ãã¾ã›ã‚“"
                    st.error(error_msg)
                    st.session_state.messages.append({"role": "assistant", "content": error_msg})
        
        if st.button("ðŸ—‘ï¸ ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ã‚¯ãƒªã‚¢"):
            st.session_state.messages = []
            st.rerun()
    
    with tab4:
        st.header("ðŸ““ Notionçµ±åˆ")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("ðŸ”„ Notionãƒ‡ãƒ¼ã‚¿æ›´æ–°"):
                if vector_db and st.secrets.get("NOTION_TOKEN"):
                    try:
                        from notion_processor import NotionProcessor
                        
                        with st.spinner("Notionãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­..."):
                            processor = NotionProcessor()
                            documents = processor.get_all_pages()
                        
                        if documents:
                            vector_db.add_documents(documents)
                            st.success(f"âœ… {len(documents)}ä»¶ã®Notionãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆã—ã¾ã—ãŸ")
                        else:
                            st.warning("âš ï¸ Notionãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                            
                    except Exception as e:
                        st.error(f"âŒ Notionå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
                else:
                    st.error("âŒ ChromaDBã¾ãŸã¯NOTION_TOKENãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
        
        with col2:
            if st.button("ðŸ“Š Notionçµ±è¨ˆæƒ…å ±") and vector_db:
                try:
                    # å…¨ä½“çµ±è¨ˆ
                    stats = vector_db.get_stats()
                    st.metric("ç·æ–‡æ›¸æ•°", stats['total_documents'])
                    
                    # Notionå›ºæœ‰ã®çµ±è¨ˆã¯æ¤œç´¢ã§å–å¾—
                    notion_results = vector_db.search("notion", n_results=100)
                    notion_docs = [r for r in notion_results if r['metadata'].get('source') == 'notion']
                    st.metric("Notionæ–‡æ›¸æ•°", len(notion_docs))
                    
                except Exception as e:
                    st.error(f"âŒ çµ±è¨ˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")

def perform_ai_analysis(query: str, results: list, analysis_type: str) -> str:
    """AIåˆ†æžå®Ÿè¡Œï¼ˆæœ€é©åŒ–ç‰ˆï¼‰"""
    
    if not st.secrets.get("OPENAI_API_KEY"):
        return "âŒ OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
    
    try:
        import openai
        openai.api_key = st.secrets["OPENAI_API_KEY"]
        
        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ§‹ç¯‰ï¼ˆæœ€é©åŒ–ï¼‰
        context_parts = []
        total_chars = 0
        max_context_chars = 12000  # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåˆ¶é™
        
        for i, result in enumerate(results[:20]):  # ä¸Šä½20ä»¶ã«åˆ¶é™
            title = result['metadata'].get('title', 'ç„¡é¡Œ')
            source = result['metadata'].get('source', 'ä¸æ˜Ž')
            content = result['content']
            similarity = 1 - result['distance']
            
            # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„é•·ã®èª¿æ•´
            if total_chars + len(content) > max_context_chars:
                remaining_chars = max_context_chars - total_chars
                content = content[:remaining_chars] + "..."
            
            context_part = f"""
ã€å‚ç…§{i+1}ã€‘{title} ({source}) - é¡žä¼¼åº¦: {similarity:.3f}
{content}
"""
            context_parts.append(context_part)
            total_chars += len(context_part)
            
            if total_chars >= max_context_chars:
                break
        
        context = "\n".join(context_parts)
        
        # åˆ†æžã‚¿ã‚¤ãƒ—åˆ¥ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆæœ€é©åŒ–ç‰ˆï¼‰
        prompts = {
            "summary": f"""
ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€Œ{query}ã€ã«ã¤ã„ã¦åŒ…æ‹¬çš„ãªè¦ç´„ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ã€è¦æ±‚äº‹é …ã€‘
- ä¸»è¦ãƒã‚¤ãƒ³ãƒˆ3-4å€‹ã«æ•´ç†
- å„ãƒã‚¤ãƒ³ãƒˆã¯ç°¡æ½”ã‹ã¤å…·ä½“çš„ã«
- é‡è¦ãªæ•°å€¤ãƒ»ãƒ‡ãƒ¼ã‚¿ã‚’æ˜Žè¨˜
- å®Ÿç”¨çš„ãªæƒ…å ±ã‚’å„ªå…ˆ

ã€å‚ç…§ãƒ‡ãƒ¼ã‚¿ã€‘
{context}

ã€å‡ºåŠ›å½¢å¼ã€‘
## ðŸ“‹ åŒ…æ‹¬çš„è¦ç´„

### ðŸŽ¯ ä¸»è¦ãƒã‚¤ãƒ³ãƒˆ
1. **ãƒã‚¤ãƒ³ãƒˆ1**: ç°¡æ½”ãªèª¬æ˜Ž
2. **ãƒã‚¤ãƒ³ãƒˆ2**: ç°¡æ½”ãªèª¬æ˜Ž
3. **ãƒã‚¤ãƒ³ãƒˆ3**: ç°¡æ½”ãªèª¬æ˜Ž

### ðŸ“Š é‡è¦ãƒ‡ãƒ¼ã‚¿
- æ•°å€¤ãƒ»çµ±è¨ˆæƒ…å ±
- é‡è¦ãªäº‹å®Ÿ

### ðŸ’¡ å®Ÿç”¨çš„ç¤ºå”†
- æ´»ç”¨å¯èƒ½ãªçŸ¥è¦‹
- æ³¨æ„ã™ã¹ãç‚¹
""",
            
            "insights": f"""
ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€Œ{query}ã€ã«ã¤ã„ã¦æ·±å±¤æ´žå¯Ÿã¨å¤šè§’çš„åˆ†æžã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚

ã€è¦æ±‚äº‹é …ã€‘
- è¡¨é¢çš„ã§ãªã„æ·±ã„æ´žå¯Ÿ
- è¤‡æ•°è¦–ç‚¹ã‹ã‚‰ã®åˆ†æž
- æ½œåœ¨çš„èª²é¡Œãƒ»æ©Ÿä¼šã®ç™ºè¦‹
- å®Ÿç”¨çš„ãªæ°—ã¥ã

ã€å‚ç…§ãƒ‡ãƒ¼ã‚¿ã€‘
{context}

ã€å‡ºåŠ›å½¢å¼ã€‘
## ðŸ’¡ æ·±å±¤æ´žå¯Ÿ

### ðŸ” æ ¸å¿ƒçš„ç™ºè¦‹
- æœ€é‡è¦ãªæ´žå¯Ÿ
- éš ã‚ŒãŸèª²é¡Œãƒ»æ©Ÿä¼š

### ðŸ“ å¤šè§’çš„åˆ†æž
**çµŒå–¶è¦–ç‚¹**: 
**ç¾å ´è¦–ç‚¹**: 
**å¸‚å ´è¦–ç‚¹**: 

### âš¡ é‡è¦è¦å› 
- æˆåŠŸè¦å› 
- ãƒªã‚¹ã‚¯è¦å› 

### ðŸ”® å°†æ¥å±•æœ›
- äºˆæƒ³ã•ã‚Œã‚‹å¤‰åŒ–
- å¯¾ç­–ã®æ–¹å‘æ€§
""",
            
            "recommendations": f"""
ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€Œ{query}ã€ã«ã¤ã„ã¦æˆ¦ç•¥çš„æŽ¨å¥¨ã¨å®Ÿè¡Œè¨ˆç”»ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚

ã€è¦æ±‚äº‹é …ã€‘
- å…·ä½“çš„ã§å®Ÿè¡Œå¯èƒ½ãªæŽ¨å¥¨
- å„ªå…ˆåº¦ä»˜ãã‚¢ã‚¯ã‚·ãƒ§ãƒ³
- æœŸå¾…åŠ¹æžœã®æ˜Žè¨˜
- å®Ÿè¡Œæ™‚ã®æ³¨æ„ç‚¹

ã€å‚ç…§ãƒ‡ãƒ¼ã‚¿ã€‘
{context}

ã€å‡ºåŠ›å½¢å¼ã€‘
## ðŸš€ æˆ¦ç•¥çš„æŽ¨å¥¨

### ðŸŽ¯ ä¸»è¦æŽ¨å¥¨äº‹é …
1. **æŽ¨å¥¨1**: å…·ä½“çš„å†…å®¹ã¨ç†ç”±
2. **æŽ¨å¥¨2**: å…·ä½“çš„å†…å®¹ã¨ç†ç”±
3. **æŽ¨å¥¨3**: å…·ä½“çš„å†…å®¹ã¨ç†ç”±

### ðŸ“‹ å®Ÿè¡Œè¨ˆç”»
#### ðŸ”¥ æœ€å„ªå…ˆï¼ˆå³æ™‚ï¼‰
- [ ] ã‚¢ã‚¯ã‚·ãƒ§ãƒ³1: è©³ç´°
- [ ] ã‚¢ã‚¯ã‚·ãƒ§ãƒ³2: è©³ç´°

#### â­ é«˜å„ªå…ˆï¼ˆ1-3ãƒ¶æœˆï¼‰
- [ ] ã‚¢ã‚¯ã‚·ãƒ§ãƒ³3: è©³ç´°

#### ðŸ“ˆ ä¸­å„ªå…ˆï¼ˆé•·æœŸï¼‰
- [ ] ã‚¢ã‚¯ã‚·ãƒ§ãƒ³4: è©³ç´°

### ðŸ“Š æœŸå¾…åŠ¹æžœ
- å®šé‡çš„åŠ¹æžœ
- å®šæ€§çš„åŠ¹æžœ

### âš ï¸ å®Ÿè¡Œæ™‚æ³¨æ„ç‚¹
- ãƒªã‚¹ã‚¯è¦å› 
- æˆåŠŸã®ãƒã‚¤ãƒ³ãƒˆ
"""
        }
        
        # AIåˆ†æžå®Ÿè¡Œ
        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[
                {
                    "role": "system",
                    "content": "ã‚ãªãŸã¯ä¼æ¥­ã®æˆ¦ç•¥ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã§ã™ã€‚æä¾›ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’åŠ¹çŽ‡çš„ã«åˆ†æžã—ã€å®Ÿç”¨çš„ã§å…·ä½“çš„ãªæ´žå¯Ÿã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚"
                },
                {
                    "role": "user",
                    "content": prompts[analysis_type]
                }
            ],
            max_tokens=1500,  # ãƒ¬ã‚¹ãƒãƒ³ã‚¹æœ€é©åŒ–
            temperature=0.7,
            timeout=30  # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®š
        )
        
        return response.choices[0].message.content
        
    except Exception as e:
        return f"âŒ AIåˆ†æžã‚¨ãƒ©ãƒ¼: {str(e)}"

def display_reference_data(results):
    """å‚ç…§ãƒ‡ãƒ¼ã‚¿è¡¨ç¤ºï¼ˆæœ€é©åŒ–ç‰ˆï¼‰"""
    
    with st.expander(f"ðŸ“š å‚ç…§ãƒ‡ãƒ¼ã‚¿è©³ç´°ï¼ˆ{len(results)}ä»¶ï¼‰"):
        
        # çµ±è¨ˆæƒ…å ±
        col1, col2, col3 = st.columns(3)
        
        with col1:
            avg_similarity = sum([1-r['distance'] for r in results]) / len(results)
            st.metric("å¹³å‡é¡žä¼¼åº¦", f"{avg_similarity:.3f}")
        
        with col2:
            sources = {}
            for r in results:
                source = r['metadata'].get('source', 'ä¸æ˜Ž')
                sources[source] = sources.get(source, 0) + 1
            st.write("**ã‚½ãƒ¼ã‚¹åˆ†å¸ƒ:**")
            for source, count in sources.items():
                st.write(f"- {source}: {count}ä»¶")
        
        with col3:
            total_chars = sum([len(r['content']) for r in results])
            st.metric("ç·å‚ç…§æ–‡å­—æ•°", f"{total_chars:,}")
        
        # ä¸Šä½å‚ç…§æ–‡æ›¸ï¼ˆç°¡æ½”ç‰ˆï¼‰
        st.write("**ä¸Šä½å‚ç…§æ–‡æ›¸:**")
        for i, result in enumerate(results[:10]):  # ä¸Šä½10ä»¶ã®ã¿
            title = result['metadata'].get('title', 'ç„¡é¡Œ')
            source = result['metadata'].get('source', 'ä¸æ˜Ž')
            similarity = 1 - result['distance']
            
            with st.expander(f"{i+1}. {title} ({source}) - é¡žä¼¼åº¦: {similarity:.3f}"):
                content_preview = result['content'][:300] + "..." if len(result['content']) > 300 else result['content']
                st.text(content_preview)

if __name__ == "__main__":
    main()
