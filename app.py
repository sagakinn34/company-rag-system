import streamlit as st
import sys
import os

# ãƒ‘ã‚¹è¨­å®š
sys.path.append('src')

st.set_page_config(
    page_title="ä¼æ¥­RAGã‚·ã‚¹ãƒ†ãƒ  v7.0",
    page_icon="ğŸ¢",
    layout="wide"
)

def check_system_requirements():
    """ã‚·ã‚¹ãƒ†ãƒ è¦ä»¶ãƒã‚§ãƒƒã‚¯"""
    st.sidebar.header("ğŸ”§ ã‚·ã‚¹ãƒ†ãƒ è¨ºæ–­")
    
    # SQLite3ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãƒã‚§ãƒƒã‚¯
    try:
        import sqlite3
        sqlite_version = sqlite3.sqlite_version
        st.sidebar.info(f"SQLite3ãƒãƒ¼ã‚¸ãƒ§ãƒ³: {sqlite_version}")
        
        # ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ¯”è¼ƒ
        version_parts = [int(x) for x in sqlite_version.split('.')]
        if version_parts >= [3, 35, 0]:
            st.sidebar.success("âœ… SQLite3ãƒãƒ¼ã‚¸ãƒ§ãƒ³: å¯¾å¿œæ¸ˆã¿")
        else:
            st.sidebar.warning("âš ï¸ SQLite3ãƒãƒ¼ã‚¸ãƒ§ãƒ³: è¦å¯¾å¿œ")
            
    except Exception as e:
        st.sidebar.error(f"âŒ SQLite3ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
    
    # ChromaDBãƒã‚§ãƒƒã‚¯
    try:
        from vector_db_processor import VectorDBProcessor
        vector_db = VectorDBProcessor()
        if vector_db.collection:
            stats = vector_db.get_stats()
            st.sidebar.success(f"âœ… ChromaDB: {stats['total_documents']}ä»¶")
            return vector_db
        else:
            st.sidebar.error("âŒ ChromaDB: åˆæœŸåŒ–å¤±æ•—")
            return None
    except Exception as e:
        st.sidebar.error(f"âŒ ChromaDBã‚¨ãƒ©ãƒ¼: {e}")
        return None

def main():
    st.title("ğŸ¢ ä¼æ¥­RAGã‚·ã‚¹ãƒ†ãƒ  v7.0 - Discordçµ±åˆç‰ˆ")
    
    # ã‚·ã‚¹ãƒ†ãƒ è¨ºæ–­
    vector_db = check_system_requirements()
    
    # ç’°å¢ƒå¤‰æ•°ãƒã‚§ãƒƒã‚¯
    with st.sidebar:
        st.header("ğŸ”‘ ç’°å¢ƒå¤‰æ•°")
        env_checks = {
            "NOTION_TOKEN": bool(st.secrets.get("NOTION_TOKEN")),
            "OPENAI_API_KEY": bool(st.secrets.get("OPENAI_API_KEY")),
            "DISCORD_TOKEN": bool(st.secrets.get("DISCORD_TOKEN")),
            "GOOGLE_DRIVE_CREDENTIALS": bool(st.secrets.get("GOOGLE_DRIVE_CREDENTIALS"))
        }
        
        for var_name, is_set in env_checks.items():
            if is_set:
                st.success(f"âœ… {var_name}")
            else:
                st.error(f"âŒ {var_name}")
        
        # ãƒ‡ãƒ¼ã‚¿çµ±åˆ
        st.header("ğŸ”„ ãƒ‡ãƒ¼ã‚¿çµ±åˆ")
        if st.button("ğŸš€ ãƒ‡ãƒ¼ã‚¿çµ±åˆå®Ÿè¡Œ"):
            if vector_db and vector_db.collection:
                try:
                    from final_integration import run_data_integration
                    result = run_data_integration()
                    if result:
                        st.success("âœ… ãƒ‡ãƒ¼ã‚¿çµ±åˆå®Œäº†")
                        st.rerun()
                    else:
                        st.warning("âš ï¸ ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                except Exception as e:
                    st.error(f"âŒ çµ±åˆã‚¨ãƒ©ãƒ¼: {e}")
            else:
                st.error("âŒ ChromaDBãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
    
    # ã‚·ã‚¹ãƒ†ãƒ ãŒæ­£å¸¸ã§ãªã„å ´åˆã®è­¦å‘Šè¡¨ç¤º
    if not vector_db or not vector_db.collection:
        st.error("ğŸš¨ ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼")
        st.markdown("""
        **ChromaDBã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚**
        
        è€ƒãˆã‚‰ã‚Œã‚‹åŸå› ï¼š
        - SQLite3ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®å•é¡Œ
        - ä¾å­˜é–¢ä¿‚ã®ç«¶åˆ
        - ãƒ¡ãƒ¢ãƒªä¸è¶³
        
        **å¯¾å‡¦æ–¹æ³•ï¼š**
        1. ãƒšãƒ¼ã‚¸ã‚’å†èª­ã¿è¾¼ã¿ã—ã¦ãã ã•ã„
        2. å•é¡ŒãŒç¶šãå ´åˆã¯ã€ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…ã«ãŠå•ã„åˆã‚ã›ãã ã•ã„
        """)
        return
    
    # æ­£å¸¸ãªå ´åˆã¯æœ¬æ¥ã®ã‚¿ãƒ–æ§‹æˆã‚’è¡¨ç¤º
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ  ãƒ›ãƒ¼ãƒ ", "ğŸ” ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢", "ğŸ’¬ AIãƒãƒ£ãƒƒãƒˆ", "ğŸ““ Notionçµ±åˆ"])
    
    with tab1:
        st.header("ğŸ  ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦")
        st.markdown("""
        ### ğŸ¯ ä¼æ¥­RAGã‚·ã‚¹ãƒ†ãƒ  v7.0ã®æ©Ÿèƒ½
        
        **ğŸ” ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹çµ±åˆ:**
        - **Notion**: ãƒšãƒ¼ã‚¸ãƒ»ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ»ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯ãƒ»ã‚¿ã‚¹ã‚¯ãƒªã‚¹ãƒˆ
        - **Google Drive**: PDFã€Wordã€Excelã€PowerPointã€ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«
        - **Discord**: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ãƒ»ãƒãƒ£ãƒ³ãƒãƒ«æƒ…å ±ï¼ˆä»Šå¾Œå®Ÿè£…ï¼‰
        
        **ğŸ¤– AIåˆ†ææ©Ÿèƒ½:**
        - **OpenAI GPT-4o**: 128,000ãƒˆãƒ¼ã‚¯ãƒ³å¯¾å¿œ
        - **RAGæ©Ÿèƒ½**: é–¢é€£æ–‡æ›¸ã‚’å‚ç…§ã—ãŸå›ç­”ç”Ÿæˆ
        - **ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢**: æ„å‘³çš„é¡ä¼¼æ€§ã«ã‚ˆã‚‹æ–‡æ›¸æ¤œç´¢
        
        **ğŸ“Š ç¾åœ¨ã®çŠ¶æ³:**
        """)
        
        # çµ±è¨ˆæƒ…å ±è¡¨ç¤º
        if vector_db:
            stats = vector_db.get_stats()
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("æ–‡æ›¸æ•°", stats['total_documents'])
            with col2:
                st.metric("ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", stats['status'])
            with col3:
                st.metric("ChromaDB", "âœ… æ­£å¸¸")
    
    with tab2:
        st.header("ğŸ” ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢")
        
        search_query = st.text_input("æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        max_results = st.slider("æœ€å¤§çµæœæ•°", 1, 20, 5)
        
        if st.button("ğŸ” æ¤œç´¢å®Ÿè¡Œ") and search_query and vector_db:
            with st.spinner("æ¤œç´¢ä¸­..."):
                results = vector_db.search(search_query, n_results=max_results)
            
            if results:
                st.success(f"âœ… {len(results)}ä»¶ã®é–¢é€£æ–‡æ›¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
                for i, result in enumerate(results):
                    with st.expander(f"ğŸ“„ çµæœ {i+1}: {result['metadata'].get('title', 'ç„¡é¡Œ')}"):
                        st.write(f"**ã‚½ãƒ¼ã‚¹**: {result['metadata'].get('source', 'ä¸æ˜')}")
                        st.write(f"**é¡ä¼¼åº¦**: {1-result['distance']:.3f}")
                        st.text(result['content'][:500] + "..." if len(result['content']) > 500 else result['content'])
            else:
                st.warning("âš ï¸ é–¢é€£ã™ã‚‹æ–‡æ›¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
    
    with tab3:
        st.header("ğŸ’¬ AIãƒãƒ£ãƒƒãƒˆï¼ˆRAGæ©Ÿèƒ½ä»˜ãï¼‰")
        
        if "messages" not in st.session_state:
            st.session_state.messages = []
        
        # ãƒãƒ£ãƒƒãƒˆå±¥æ­´è¡¨ç¤º
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
        if prompt := st.chat_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„..."):
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)
            
            # AIå¿œç­”ç”Ÿæˆ
            with st.chat_message("assistant"):
                if vector_db and st.secrets.get("OPENAI_API_KEY"):
                    try:
                        # é–¢é€£æ–‡æ›¸æ¤œç´¢
                        relevant_docs = vector_db.search(prompt, n_results=3)
                        
                        # OpenAI APIå‘¼ã³å‡ºã—
                        import openai
                        openai.api_key = st.secrets["OPENAI_API_KEY"]
                        
                        context = ""
                        if relevant_docs:
                            context = "\n\n".join([doc['content'][:300] for doc in relevant_docs])
                        
                        messages = [
                            {"role": "system", "content": f"""ã‚ãªãŸã¯ä¼æ¥­ã®æƒ…å ±ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®é–¢é€£æ–‡æ›¸ã‚’å‚è€ƒã«ã—ã¦è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚

é–¢é€£æ–‡æ›¸:
{context}

å›ç­”ã¯æ—¥æœ¬èªã§ç°¡æ½”ã«ç­”ãˆã¦ãã ã•ã„ã€‚"""},
                            {"role": "user", "content": prompt}
                        ]
                        
                        response = openai.ChatCompletion.create(
                            model="gpt-4",
                            messages=messages,
                            max_tokens=1000,
                            temperature=0.7
                        )
                        
                        ai_response = response.choices[0].message.content
                        st.markdown(ai_response)
                        st.session_state.messages.append({"role": "assistant", "content": ai_response})
                        
                    except Exception as e:
                        error_msg = f"âŒ AIå¿œç­”ã‚¨ãƒ©ãƒ¼: {e}"
                        st.error(error_msg)
                        st.session_state.messages.append({"role": "assistant", "content": error_msg})
                else:
                    error_msg = "âŒ ChromaDBã¾ãŸã¯OpenAI APIãŒåˆ©ç”¨ã§ãã¾ã›ã‚“"
                    st.error(error_msg)
                    st.session_state.messages.append({"role": "assistant", "content": error_msg})
        
        if st.button("ğŸ—‘ï¸ ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ã‚¯ãƒªã‚¢"):
            st.session_state.messages = []
            st.rerun()
    
    with tab4:
        st.header("ğŸ““ Notionçµ±åˆ")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("ğŸ”„ Notionãƒ‡ãƒ¼ã‚¿æ›´æ–°"):
                if vector_db and st.secrets.get("NOTION_TOKEN"):
                    try:
                        from notion_processor import NotionProcessor
                        
                        with st.spinner("Notionãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­..."):
                            processor = NotionProcessor()
                            documents = processor.get_all_pages()
                        
                        if documents:
                            vector_db.add_documents(documents)
                            st.success(f"âœ… {len(documents)}ä»¶ã®Notionãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆã—ã¾ã—ãŸ")
                        else:
                            st.warning("âš ï¸ Notionãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                            
                    except Exception as e:
                        st.error(f"âŒ Notionå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
                else:
                    st.error("âŒ ChromaDBã¾ãŸã¯NOTION_TOKENãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
        
        with col2:
            if st.button("ğŸ“Š Notionçµ±è¨ˆæƒ…å ±") and vector_db:
                try:
                    # å…¨ä½“çµ±è¨ˆ
                    stats = vector_db.get_stats()
                    st.metric("ç·æ–‡æ›¸æ•°", stats['total_documents'])
                    
                    # Notionå›ºæœ‰ã®çµ±è¨ˆã¯æ¤œç´¢ã§å–å¾—
                    notion_results = vector_db.search("notion", n_results=100)
                    notion_docs = [r for r in notion_results if r['metadata'].get('source') == 'notion']
                    st.metric("Notionæ–‡æ›¸æ•°", len(notion_docs))
                    
                except Exception as e:
                    st.error(f"âŒ çµ±è¨ˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")

if __name__ == "__main__":
    main()
