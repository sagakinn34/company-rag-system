import streamlit as st
import sys
import os

# ãƒ‘ã‚¹è¨­å®š
sys.path.append('src')

st.set_page_config(
    page_title="ä¼æ¥­RAGã‚·ã‚¹ãƒ†ãƒ  v7.0",
    page_icon="ðŸ¢",
    layout="wide"
)

def check_system_requirements():
    """ã‚·ã‚¹ãƒ†ãƒ è¦ä»¶ãƒã‚§ãƒƒã‚¯"""
    st.sidebar.header("ðŸ”§ ã‚·ã‚¹ãƒ†ãƒ è¨ºæ–­")
    
    # SQLite3ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãƒã‚§ãƒƒã‚¯
    try:
        import sqlite3
        sqlite_version = sqlite3.sqlite_version
        st.sidebar.info(f"SQLite3ãƒãƒ¼ã‚¸ãƒ§ãƒ³: {sqlite_version}")
        
        # ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ¯”è¼ƒ
        version_parts = [int(x) for x in sqlite_version.split('.')]
        if version_parts >= [3, 35, 0]:
            st.sidebar.success("âœ… SQLite3ãƒãƒ¼ã‚¸ãƒ§ãƒ³: å¯¾å¿œæ¸ˆã¿")
        else:
            st.sidebar.warning("âš ï¸ SQLite3ãƒãƒ¼ã‚¸ãƒ§ãƒ³: è¦å¯¾å¿œ")
            
    except Exception as e:
        st.sidebar.error(f"âŒ SQLite3ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
    
    # ChromaDBãƒã‚§ãƒƒã‚¯
    try:
        from vector_db_processor import VectorDBProcessor
        vector_db = VectorDBProcessor()
        if vector_db.collection:
            stats = vector_db.get_stats()
            st.sidebar.success(f"âœ… ChromaDB: {stats['total_documents']}ä»¶")
            return vector_db
        else:
            st.sidebar.error("âŒ ChromaDB: åˆæœŸåŒ–å¤±æ•—")
            return None
    except Exception as e:
        st.sidebar.error(f"âŒ ChromaDBã‚¨ãƒ©ãƒ¼: {e}")
        return None

def main():
    st.title("ðŸ¢ ä¼æ¥­RAGã‚·ã‚¹ãƒ†ãƒ  v7.0 - GPT-4oå¤§å®¹é‡å¯¾å¿œç‰ˆ")
    
    # ã‚·ã‚¹ãƒ†ãƒ è¨ºæ–­
    vector_db = check_system_requirements()
    
    # ç’°å¢ƒå¤‰æ•°ãƒã‚§ãƒƒã‚¯
    with st.sidebar:
        st.header("ðŸ”‘ ç’°å¢ƒå¤‰æ•°")
        env_checks = {
            "NOTION_TOKEN": bool(st.secrets.get("NOTION_TOKEN")),
            "OPENAI_API_KEY": bool(st.secrets.get("OPENAI_API_KEY")),
            "DISCORD_TOKEN": bool(st.secrets.get("DISCORD_TOKEN")),
            "GOOGLE_DRIVE_CREDENTIALS": bool(st.secrets.get("GOOGLE_DRIVE_CREDENTIALS"))
        }
        
        for var_name, is_set in env_checks.items():
            if is_set:
                st.success(f"âœ… {var_name}")
            else:
                st.error(f"âŒ {var_name}")
        
        # ãƒ‡ãƒ¼ã‚¿çµ±åˆ
        st.header("ðŸ”„ ãƒ‡ãƒ¼ã‚¿çµ±åˆ")
        if st.button("ðŸš€ æœ€é©åŒ–çµ±åˆå®Ÿè¡Œ"):
            if vector_db and vector_db.collection:
                try:
                    from final_integration import run_data_integration
                    result = run_data_integration()
                    if result:
                        st.success("âœ… æœ€é©åŒ–çµ±åˆå®Œäº†")
                        st.rerun()
                    else:
                        st.warning("âš ï¸ ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                except Exception as e:
                    st.error(f"âŒ çµ±åˆã‚¨ãƒ©ãƒ¼: {e}")
            else:
                st.error("âŒ ChromaDBãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
    
    # ã‚·ã‚¹ãƒ†ãƒ ãŒæ­£å¸¸ã§ãªã„å ´åˆã®è­¦å‘Šè¡¨ç¤º
    if not vector_db or not vector_db.collection:
        st.error("ðŸš¨ ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼")
        st.markdown("""
        **ChromaDBã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚**
        
        è€ƒãˆã‚‰ã‚Œã‚‹åŽŸå› ï¼š
        - SQLite3ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®å•é¡Œ
        - ä¾å­˜é–¢ä¿‚ã®ç«¶åˆ
        - ãƒ¡ãƒ¢ãƒªä¸è¶³
        
        **å¯¾å‡¦æ–¹æ³•ï¼š**
        1. ãƒšãƒ¼ã‚¸ã‚’å†èª­ã¿è¾¼ã¿ã—ã¦ãã ã•ã„
        2. å•é¡ŒãŒç¶šãå ´åˆã¯ã€ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…ã«ãŠå•ã„åˆã‚ã›ãã ã•ã„
        """)
        return
    
    # æ­£å¸¸ãªå ´åˆã¯æœ¬æ¥ã®ã‚¿ãƒ–æ§‹æˆã‚’è¡¨ç¤º
    tab1, tab2, tab3, tab4 = st.tabs(["ðŸ  ãƒ›ãƒ¼ãƒ ", "ðŸ” é«˜åº¦æ¤œç´¢ãƒ»åˆ†æž", "ðŸ’¬ AIãƒãƒ£ãƒƒãƒˆ", "ðŸ““ Notionçµ±åˆ"])
    
    with tab1:
        st.header("ðŸ  ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦")
        st.markdown("""
        ### ðŸŽ¯ ä¼æ¥­RAGã‚·ã‚¹ãƒ†ãƒ  v7.0ã®æ©Ÿèƒ½ï¼ˆGPT-4oå¤§å®¹é‡å¯¾å¿œç‰ˆï¼‰
        
        **ðŸ” ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹çµ±åˆ:**
        - **Notion**: ãƒšãƒ¼ã‚¸ãƒ»ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼ˆ150ä»¶ä¸Šé™ï¼‰
        - **Google Drive**: PDFã€Wordã€Excelã€PowerPointï¼ˆ100ä»¶ä¸Šé™ï¼‰
        - **Discord**: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ï¼ˆä»Šå¾Œå®Ÿè£…ï¼‰
        
        **ðŸ¤– AIåˆ†æžæ©Ÿèƒ½:**
        - **OpenAI GPT-4o**: 128,000ãƒˆãƒ¼ã‚¯ãƒ³å¯¾å¿œ
        - **é«˜åº¦åˆ†æž**: åŒ…æ‹¬çš„è¦ç´„ãƒ»æ·±å±¤æ´žå¯Ÿãƒ»æˆ¦ç•¥çš„æŽ¨å¥¨
        - **å¤§å®¹é‡å‡¦ç†**: æœ€å¤§50ä»¶å‚ç…§ãƒ»5ä¸‡æ–‡å­—å‡¦ç†
        - **ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢**: æ„å‘³çš„é¡žä¼¼æ€§ã«ã‚ˆã‚‹æ–‡æ›¸æ¤œç´¢
        
        **âš–ï¸ æœ€é©åŒ–ç‰¹å¾´:**
        - **å®Ÿç”¨æ€§**: ååˆ†ãªæƒ…å ±é‡ï¼ˆ250ä»¶ï¼‰
        - **å¯ç”¨æ€§**: å®‰å®šã—ãŸå‹•ä½œï¼ˆå‡¦ç†æ™‚é–“çŸ­ç¸®ï¼‰
        - **å¤§å®¹é‡**: GPT-4oã®128Kãƒˆãƒ¼ã‚¯ãƒ³ãƒ•ãƒ«æ´»ç”¨
        
        **ðŸ“Š ç¾åœ¨ã®çŠ¶æ³:**
        """)
        
        # çµ±è¨ˆæƒ…å ±è¡¨ç¤º
        if vector_db:
            stats = vector_db.get_stats()
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("æ–‡æ›¸æ•°", stats['total_documents'])
            with col2:
                st.metric("ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", stats['status'])
            with col3:
                st.metric("AI Model", "GPT-4o (128K)")
    
    with tab2:
        st.header("ðŸ” é«˜åº¦æ¤œç´¢ãƒ»åˆ†æžã‚·ã‚¹ãƒ†ãƒ ï¼ˆGPT-4oå¤§å®¹é‡å¯¾å¿œï¼‰")
        
        # æ¤œç´¢ã‚¯ã‚¨ãƒªå…¥åŠ›
        search_query = st.text_input(
            "ðŸ” æ¤œç´¢ãƒ»åˆ†æžã‚¯ã‚¨ãƒªã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
            placeholder="ä¾‹: å–¶æ¥­æˆ¦ç•¥ã«ã¤ã„ã¦ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆé€²æ—ã«ã¤ã„ã¦ã€æŠ€è¡“çš„èª²é¡Œã«ã¤ã„ã¦"
        )
        
        # æ¤œç´¢ãƒ¢ãƒ¼ãƒ‰é¸æŠž
        search_mode = st.radio(
            "æ¤œç´¢ãƒ¢ãƒ¼ãƒ‰:",
            ["ðŸ” æ¨™æº–æ¤œç´¢", "ðŸ§  é«˜åº¦åˆ†æžï¼ˆGPT-4oï¼‰"],
            horizontal=True
        )
        
        if search_mode == "ðŸ” æ¨™æº–æ¤œç´¢":
            # æ—¢å­˜ã®æ¨™æº–æ¤œç´¢
            max_results = st.slider("æœ€å¤§çµæžœæ•°", 1, 20, 5)
            
            if st.button("ðŸ” æ¤œç´¢å®Ÿè¡Œ") and search_query and vector_db:
                with st.spinner("æ¤œç´¢ä¸­..."):
                    results = vector_db.search(search_query, n_results=max_results)
                
                if results:
                    st.success(f"âœ… {len(results)}ä»¶ã®é–¢é€£æ–‡æ›¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
                    for i, result in enumerate(results):
                        with st.expander(f"ðŸ“„ çµæžœ {i+1}: {result['metadata'].get('title', 'ç„¡é¡Œ')}"):
                            st.write(f"**ã‚½ãƒ¼ã‚¹**: {result['metadata'].get('source', 'ä¸æ˜Ž')}")
                            st.write(f"**é¡žä¼¼åº¦**: {1-result['distance']:.3f}")
                            st.text(result['content'][:500] + "..." if len(result['content']) > 500 else result['content'])
                else:
                    st.warning("âš ï¸ é–¢é€£ã™ã‚‹æ–‡æ›¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        
        else:  # é«˜åº¦åˆ†æžãƒ¢ãƒ¼ãƒ‰ï¼ˆGPT-4oï¼‰
            # GPT-4oå¤§å®¹é‡åˆ†æžè¨­å®š
            with st.expander("âš™ï¸ GPT-4oé«˜åº¦åˆ†æžè¨­å®š", expanded=True):
                col1, col2 = st.columns(2)
                
                with col1:
                    analysis_type = st.selectbox(
                        "ðŸ“Š åˆ†æžã‚¿ã‚¤ãƒ—:",
                        options=["summary", "insights", "recommendations"],
                        format_func=lambda x: {
                            "summary": "ðŸ“‹ åŒ…æ‹¬çš„è¦ç´„ï¼ˆè©³ç´°ç‰ˆï¼‰",
                            "insights": "ðŸ’¡ æ·±å±¤æ´žå¯Ÿï¼ˆå¤šè§’çš„åˆ†æžï¼‰",
                            "recommendations": "ðŸš€ æˆ¦ç•¥çš„æŽ¨å¥¨ï¼ˆå®Ÿè¡Œè¨ˆç”»ä»˜ãï¼‰"
                        }[x]
                    )
                
                with col2:
                    max_results = st.slider(
                        "ðŸ“š å‚ç…§ãƒ‡ãƒ¼ã‚¿æ•°",
                        min_value=10,
                        max_value=50,  # GPT-4oãªã‚‰50ä»¶ã§ã‚‚å•é¡Œãªã—
                        value=30,      # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’30ã«
                        help="GPT-4oã®128Kãƒˆãƒ¼ã‚¯ãƒ³ã§å¤§å®¹é‡å‡¦ç†å¯èƒ½"
                    )
                
                # GPT-4oæ€§èƒ½æƒ…å ±
                st.info("""
                ðŸš€ **GPT-4oå¤§å®¹é‡å‡¦ç†ãƒ¢ãƒ¼ãƒ‰**
                - **ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™**: 128,000ãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆç´„10ä¸‡æ–‡å­—ï¼‰
                - **å‡¦ç†èƒ½åŠ›**: 50ä»¶ã®æ–‡æ›¸ã‚’è©³ç´°åˆ†æžå¯èƒ½
                - **å¿œç­”å“è³ª**: é«˜åº¦ã§åŒ…æ‹¬çš„ãªåˆ†æžçµæžœ
                """)
            
            # GPT-4oé«˜åº¦åˆ†æžå®Ÿè¡Œ
            if st.button("ðŸš€ GPT-4oé«˜åº¦åˆ†æžå®Ÿè¡Œ", type="primary") and search_query and vector_db:
                with st.spinner("ðŸ§  GPT-4oå¤§å®¹é‡åˆ†æžå®Ÿè¡Œä¸­..."):
                    # ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢
                    results = vector_db.search(search_query, n_results=max_results)
                    
                    if results:
                        st.success(f"âœ… {len(results)}ä»¶ã®é–¢é€£ãƒ‡ãƒ¼ã‚¿ã‚’ç™ºè¦‹")
                        
                        # GPT-4o AIåˆ†æžå®Ÿè¡Œ
                        analysis_result = perform_ai_analysis_gpt4o(search_query, results, analysis_type)
                        
                        # çµæžœè¡¨ç¤º
                        st.markdown("---")
                        st.markdown(f"## ðŸŽ¯ ã€Œ{search_query}ã€ã®GPT-4oåˆ†æžçµæžœ")
                        st.markdown(analysis_result)
                        
                        # å‚ç…§ãƒ‡ãƒ¼ã‚¿è©³ç´°
                        display_reference_data_comprehensive(results)
                        
                    else:
                        st.warning("âš ï¸ é–¢é€£ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
    
    with tab3:
        st.header("ðŸ’¬ AIãƒãƒ£ãƒƒãƒˆï¼ˆRAGæ©Ÿèƒ½ä»˜ããƒ»GPT-4oï¼‰")
        
        if "messages" not in st.session_state:
            st.session_state.messages = []
        
        # ãƒãƒ£ãƒƒãƒˆå±¥æ­´è¡¨ç¤º
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
        if prompt := st.chat_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„..."):
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)
            
            # AIå¿œç­”ç”Ÿæˆ
            with st.chat_message("assistant"):
                if vector_db and st.secrets.get("OPENAI_API_KEY"):
                    try:
                        # é–¢é€£æ–‡æ›¸æ¤œç´¢
                        relevant_docs = vector_db.search(prompt, n_results=5)
                        
                        # OpenAI APIå‘¼ã³å‡ºã—ï¼ˆGPT-4oï¼‰
                        import openai
                        openai.api_key = st.secrets["OPENAI_API_KEY"]
                        
                        context = ""
                        if relevant_docs:
                            context = "\n\n".join([doc['content'][:500] for doc in relevant_docs])
                        
                        messages = [
                            {"role": "system", "content": f"""ã‚ãªãŸã¯ä¼æ¥­ã®æƒ…å ±ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®é–¢é€£æ–‡æ›¸ã‚’å‚è€ƒã«ã—ã¦è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚

é–¢é€£æ–‡æ›¸:
{context}

å›žç­”ã¯æ—¥æœ¬èªžã§è©³ç´°ã‹ã¤å®Ÿç”¨çš„ã«ç­”ãˆã¦ãã ã•ã„ã€‚GPT-4oã®å¤§å®¹é‡å‡¦ç†èƒ½åŠ›ã‚’æ´»ç”¨ã—ã¦ã€åŒ…æ‹¬çš„ãªå›žç­”ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚"""},
                            {"role": "user", "content": prompt}
                        ]
                        
                        response = openai.ChatCompletion.create(
                            model="gpt-4o",  # GPT-4oã«å¤‰æ›´
                            messages=messages,
                            max_tokens=2000,  # ãƒ¬ã‚¹ãƒãƒ³ã‚¹é‡ã‚’å¢—åŠ 
                            temperature=0.7
                        )
                        
                        ai_response = response.choices[0].message.content
                        st.markdown(ai_response)
                        st.session_state.messages.append({"role": "assistant", "content": ai_response})
                        
                    except Exception as e:
                        error_msg = f"âŒ AIå¿œç­”ã‚¨ãƒ©ãƒ¼: {e}"
                        st.error(error_msg)
                        st.session_state.messages.append({"role": "assistant", "content": error_msg})
                else:
                    error_msg = "âŒ ChromaDBã¾ãŸã¯OpenAI APIãŒåˆ©ç”¨ã§ãã¾ã›ã‚“"
                    st.error(error_msg)
                    st.session_state.messages.append({"role": "assistant", "content": error_msg})
        
        if st.button("ðŸ—‘ï¸ ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ã‚¯ãƒªã‚¢"):
            st.session_state.messages = []
            st.rerun()
    
    with tab4:
        st.header("ðŸ““ Notionçµ±åˆ")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("ðŸ”„ Notionãƒ‡ãƒ¼ã‚¿æ›´æ–°"):
                if vector_db and st.secrets.get("NOTION_TOKEN"):
                    try:
                        from notion_processor import NotionProcessor
                        
                        with st.spinner("Notionãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­..."):
                            processor = NotionProcessor()
                            documents = processor.get_all_pages()
                        
                        if documents:
                            vector_db.add_documents(documents)
                            st.success(f"âœ… {len(documents)}ä»¶ã®Notionãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆã—ã¾ã—ãŸ")
                        else:
                            st.warning("âš ï¸ Notionãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                            
                    except Exception as e:
                        st.error(f"âŒ Notionå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
                else:
                    st.error("âŒ ChromaDBã¾ãŸã¯NOTION_TOKENãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
        
        with col2:
            if st.button("ðŸ“Š Notionçµ±è¨ˆæƒ…å ±") and vector_db:
                try:
                    # å…¨ä½“çµ±è¨ˆ
                    stats = vector_db.get_stats()
                    st.metric("ç·æ–‡æ›¸æ•°", stats['total_documents'])
                    
                    # Notionå›ºæœ‰ã®çµ±è¨ˆã¯æ¤œç´¢ã§å–å¾—
                    notion_results = vector_db.search("notion", n_results=100)
                    notion_docs = [r for r in notion_results if r['metadata'].get('source') == 'notion']
                    st.metric("Notionæ–‡æ›¸æ•°", len(notion_docs))
                    
                except Exception as e:
                    st.error(f"âŒ çµ±è¨ˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")

def perform_ai_analysis_gpt4o(query: str, results: list, analysis_type: str) -> str:
    """GPT-4o AIåˆ†æžå®Ÿè¡Œï¼ˆ128Kå¤§å®¹é‡å¯¾å¿œï¼‰"""
    
    if not st.secrets.get("OPENAI_API_KEY"):
        return "âŒ OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
    
    try:
        import openai
        openai.api_key = st.secrets["OPENAI_API_KEY"]
        
        # GPT-4oå¤§å®¹é‡ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ§‹ç¯‰
        context = build_comprehensive_context_gpt4o(results, query)
        
        # è©³ç´°ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
        prompt = get_detailed_prompt_gpt4o(query, context, analysis_type)
        
        # GPT-4oåˆ†æžå®Ÿè¡Œ
        response = openai.ChatCompletion.create(
            model="gpt-4o",  # GPT-4oã‚’æ˜Žç¤ºçš„ã«æŒ‡å®š
            messages=[
                {
                    "role": "system",
                    "content": """ã‚ãªãŸã¯ä¼æ¥­ã®ä¸Šç´šæˆ¦ç•¥ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã§ã™ã€‚GPT-4oã®128,000ãƒˆãƒ¼ã‚¯ãƒ³ã®å¤§å®¹é‡å‡¦ç†èƒ½åŠ›ã‚’æ´»ç”¨ã—ã¦ã€
                    æä¾›ã•ã‚ŒãŸå¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç·åˆçš„ã«åˆ†æžã—ã€æ·±ã„æ´žå¯Ÿã¨å®Ÿç”¨çš„ãªæˆ¦ç•¥ææ¡ˆã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚
                    åŒ…æ‹¬çš„ã§è©³ç´°ãªåˆ†æžã‚’è¡Œã„ã€ãƒ“ã‚¸ãƒã‚¹ä¾¡å€¤ã®é«˜ã„æ´žå¯Ÿã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚"""
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            max_tokens=4000,  # è©³ç´°ãªãƒ¬ã‚¹ãƒãƒ³ã‚¹
            temperature=0.7,
            timeout=120  # 2åˆ†ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
        )
        
        return response.choices[0].message.content
        
    except Exception as e:
        return f"âŒ GPT-4oåˆ†æžã‚¨ãƒ©ãƒ¼: {str(e)}\n\nðŸ’¡ ãƒ’ãƒ³ãƒˆ: ãƒ‡ãƒ¼ã‚¿é‡ãŒå¤šã„å ´åˆã¯å‚ç…§ãƒ‡ãƒ¼ã‚¿æ•°ã‚’èª¿æ•´ã—ã¦ãã ã•ã„ã€‚"

def build_comprehensive_context_gpt4o(results: list, query: str) -> str:
    """GPT-4oç”¨åŒ…æ‹¬çš„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ§‹ç¯‰ï¼ˆ128Kå¯¾å¿œï¼‰"""
    
    context_parts = []
    
    # GPT-4oãªã‚‰å¤§å®¹é‡å‡¦ç†å¯èƒ½
    for i, result in enumerate(results):
        title = result['metadata'].get('title', 'ç„¡é¡Œ')
        source = result['metadata'].get('source', 'ä¸æ˜Ž')
        content = result['content']
        similarity = 1 - result['distance']
        category = result.get('category', 'ä¸€èˆ¬')
        
        # è©³ç´°ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä½œæˆï¼ˆæ–‡å­—æ•°åˆ¶é™ãªã—ï¼‰
        context_part = f"""
=== å‚ç…§æ–‡æ›¸ {i+1} ===
ã€ã‚¿ã‚¤ãƒˆãƒ«ã€‘{title}
ã€ã‚½ãƒ¼ã‚¹ã€‘{source}
ã€ã‚«ãƒ†ã‚´ãƒªã€‘{category}
ã€é¡žä¼¼åº¦ã€‘{similarity:.3f}
ã€å†…å®¹ã€‘
{content}

"""
        context_parts.append(context_part)
    
    comprehensive_context = "".join(context_parts)
    
    # GPT-4oã®128Kãƒˆãƒ¼ã‚¯ãƒ³å†…ã«åŽã¾ã‚‹ã‚ˆã†èª¿æ•´ï¼ˆç´„10ä¸‡æ–‡å­—ä»¥ä¸‹ï¼‰
    if len(comprehensive_context) > 100000:
        # å¿…è¦ã«å¿œã˜ã¦ä¸Šä½çµæžœã®ã¿ã«åˆ¶é™
        truncated_parts = context_parts[:int(len(context_parts) * 0.8)]
        comprehensive_context = "".join(truncated_parts)
        comprehensive_context += "\n\nâ€»æ³¨: å¤§å®¹é‡ãƒ‡ãƒ¼ã‚¿ã®ãŸã‚ä¸€éƒ¨ã‚’é¸æŠœã—ã¦åˆ†æžã—ã¦ã„ã¾ã™ã€‚"
    
    return comprehensive_context

def get_detailed_prompt_gpt4o(query: str, context: str, analysis_type: str) -> str:
    """GPT-4oç”¨è©³ç´°ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆ128Kå¯¾å¿œï¼‰"""
    
    prompts = {
        "summary": f"""
ä»¥ä¸‹ã®å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€Œ{query}ã€ã«ã¤ã„ã¦åŒ…æ‹¬çš„ã§è©³ç´°ãªè¦ç´„ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ã€åˆ†æžè¦æ±‚ã€‘
- ä¸»è¦ãƒã‚¤ãƒ³ãƒˆã‚’5-7å€‹ã«æ•´ç†
- å„ãƒã‚¤ãƒ³ãƒˆã«ã¤ã„ã¦è©³ç´°ã§å…·ä½“çš„ãªèª¬æ˜Ž
- é‡è¦ãªæ•°å€¤ãƒ»ãƒ‡ãƒ¼ã‚¿ãƒ»äº‹å®Ÿã‚’å…¨ã¦æ˜Žè¨˜
- ãƒ‡ãƒ¼ã‚¿é–“ã®é–¢é€£æ€§ã‚„ä¸€è²«æ€§ã®åˆ†æž
- ç•°ãªã‚‹è¦–ç‚¹ã‹ã‚‰ã®å¤šè§’çš„è€ƒå¯Ÿ
- å®Ÿç”¨çš„ã§å…·ä½“çš„ãªç¤ºå”†

ã€å‡ºåŠ›å½¢å¼ã€‘
## ðŸ“‹ åŒ…æ‹¬çš„è¦ç´„ï¼ˆè©³ç´°ç‰ˆï¼‰

### ðŸŽ¯ ä¸»è¦ç™ºè¦‹äº‹é …
1. **ç™ºè¦‹1**: è©³ç´°ãªèª¬æ˜Žã¨æ ¹æ‹ 
2. **ç™ºè¦‹2**: è©³ç´°ãªèª¬æ˜Žã¨æ ¹æ‹ 
3. **ç™ºè¦‹3**: è©³ç´°ãªèª¬æ˜Žã¨æ ¹æ‹ 
4. **ç™ºè¦‹4**: è©³ç´°ãªèª¬æ˜Žã¨æ ¹æ‹ 
5. **ç™ºè¦‹5**: è©³ç´°ãªèª¬æ˜Žã¨æ ¹æ‹ 

### ðŸ“Š é‡è¦ãƒ‡ãƒ¼ã‚¿ãƒ»çµ±è¨ˆ
- æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°åˆ†æž
- é‡è¦ãªçµ±è¨ˆæƒ…å ±
- ãƒˆãƒ¬ãƒ³ãƒ‰ã‚„å¤‰åŒ–ã®åˆ†æž

### ðŸ”— ãƒ‡ãƒ¼ã‚¿é–“ã®é–¢é€£æ€§
- æ–‡æ›¸é–“ã®ä¸€è²«æ€§åˆ†æž
- çŸ›ç›¾ç‚¹ã‚„èª²é¡Œã®ç‰¹å®š
- ç›¸äº’é–¢ä¿‚ã®åˆ†æž

### ðŸ’¡ å®Ÿç”¨çš„ç¤ºå”†
- æ´»ç”¨å¯èƒ½ãªå…·ä½“çš„çŸ¥è¦‹
- æ³¨æ„ã™ã¹ãé‡è¦ãªãƒã‚¤ãƒ³ãƒˆ
- ä»Šå¾Œã®æ–¹å‘æ€§

### ðŸ“ˆ ç·åˆè©•ä¾¡
- å…¨ä½“çš„ãªçŠ¶æ³è©•ä¾¡
- å¼·ã¿ãƒ»å¼±ã¿ã®åˆ†æž

ã€å‚ç…§ãƒ‡ãƒ¼ã‚¿ã€‘
{context}
""",

        "insights": f"""
ä»¥ä¸‹ã®å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€Œ{query}ã€ã«ã¤ã„ã¦æ·±å±¤çš„ãªæ´žå¯Ÿã¨å¤šè§’çš„åˆ†æžã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚

ã€åˆ†æžè¦æ±‚ã€‘
- è¡¨é¢çš„ã§ãªã„æ·±ã„æ´žå¯Ÿã®ç™ºè¦‹
- è¤‡æ•°ã®è¦–ç‚¹ã‹ã‚‰ã®åŒ…æ‹¬çš„åˆ†æž
- æ½œåœ¨çš„ãªèª²é¡Œãƒ»æ©Ÿä¼šãƒ»ãƒªã‚¹ã‚¯ã®ç‰¹å®š
- æ¥­ç•Œå‹•å‘ã‚„å°†æ¥äºˆæ¸¬
- æˆ¦ç•¥çš„å«æ„ã®åˆ†æž
- ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ãªæˆåŠŸè¦å› ã®ç‰¹å®š

ã€å‡ºåŠ›å½¢å¼ã€‘
## ðŸ’¡ æ·±å±¤æ´žå¯Ÿï¼ˆå¤šè§’çš„åˆ†æžï¼‰

### ðŸ” æ ¸å¿ƒçš„ç™ºè¦‹
- æœ€ã‚‚é‡è¦ã§æ·±ã„æ´žå¯Ÿ
- éš ã‚ŒãŸèª²é¡Œãƒ»æ©Ÿä¼šã®ç™ºè¦‹
- æ„å¤–ãªç™ºè¦‹ã‚„æ°—ã¥ã

### ðŸ“ å¤šè§’çš„åˆ†æž
**ðŸ¢ çµŒå–¶è¦–ç‚¹**
- çµŒå–¶å±¤ãŒæ³¨ç›®ã™ã¹ããƒã‚¤ãƒ³ãƒˆ
- æˆ¦ç•¥çš„å«æ„

**ðŸ‘¥ ç¾å ´è¦–ç‚¹**
- å®Ÿå‹™ã¸ã®å½±éŸ¿
- ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®èª²é¡Œãƒ»æ©Ÿä¼š

**ðŸ“ˆ å¸‚å ´ãƒ»é¡§å®¢è¦–ç‚¹**
- å¸‚å ´å‹•å‘ã¨ã®é–¢é€£
- é¡§å®¢ã¸ã®å½±éŸ¿

**ðŸ’° è²¡å‹™ãƒ»ãƒªã‚¹ã‚¯è¦–ç‚¹**
- è²¡å‹™çš„ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ
- ãƒªã‚¹ã‚¯è¦å› 

### âš¡ ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«è¦å› 
- æˆåŠŸã‚’å·¦å³ã™ã‚‹é‡è¦è¦å› 
- æ³¨æ„ã™ã¹ããƒªã‚¹ã‚¯è¦å› 
- ç«¶äº‰å„ªä½ã®æºæ³‰

### ðŸ”® å°†æ¥å±•æœ›ãƒ»äºˆæ¸¬
- äºˆæƒ³ã•ã‚Œã‚‹å±•é–‹
- æ³¨æ„ã™ã¹ããƒˆãƒ¬ãƒ³ãƒ‰
- é•·æœŸçš„ãªå½±éŸ¿

### ðŸŽ¯ æˆ¦ç•¥çš„å«æ„
- æˆ¦ç•¥ã¸ã®å½±éŸ¿
- æ„æ€æ±ºå®šã¸ã®ç¤ºå”†

ã€å‚ç…§ãƒ‡ãƒ¼ã‚¿ã€‘
{context}
""",

        "recommendations": f"""
ä»¥ä¸‹ã®å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€Œ{query}ã€ã«ã¤ã„ã¦æˆ¦ç•¥çš„æŽ¨å¥¨äº‹é …ã¨è©³ç´°ãªå®Ÿè¡Œè¨ˆç”»ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚

ã€åˆ†æžè¦æ±‚ã€‘
- å…·ä½“çš„ã§å®Ÿè¡Œå¯èƒ½ãªæŽ¨å¥¨äº‹é …
- å„ªå…ˆåº¦ã¨ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ä»˜ãã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³
- æœŸå¾…ã•ã‚Œã‚‹åŠ¹æžœã¨KPIã®æ˜Žç¢ºåŒ–
- å®Ÿè¡Œæ™‚ã®ãƒªã‚¹ã‚¯ã¨å¯¾ç­–
- å¿…è¦ãªãƒªã‚½ãƒ¼ã‚¹ã¨ä½“åˆ¶
- æˆåŠŸè¦å› ã¨æ³¨æ„ç‚¹

ã€å‡ºåŠ›å½¢å¼ã€‘
## ðŸš€ æˆ¦ç•¥çš„æŽ¨å¥¨ï¼ˆå®Ÿè¡Œè¨ˆç”»ä»˜ãï¼‰

### ðŸŽ¯ ä¸»è¦æŽ¨å¥¨äº‹é …
1. **æŽ¨å¥¨äº‹é …1**: 
   - å†…å®¹: è©³ç´°ãªèª¬æ˜Ž
   - ç†ç”±: æ ¹æ‹ ã¨æœŸå¾…åŠ¹æžœ
   - å„ªå…ˆåº¦: é«˜/ä¸­/ä½Ž

2. **æŽ¨å¥¨äº‹é …2**:
   - å†…å®¹: è©³ç´°ãªèª¬æ˜Ž
   - ç†ç”±: æ ¹æ‹ ã¨æœŸå¾…åŠ¹æžœ
   - å„ªå…ˆåº¦: é«˜/ä¸­/ä½Ž

3. **æŽ¨å¥¨äº‹é …3**:
   - å†…å®¹: è©³ç´°ãªèª¬æ˜Ž
   - ç†ç”±: æ ¹æ‹ ã¨æœŸå¾…åŠ¹æžœ
   - å„ªå…ˆåº¦: é«˜/ä¸­/ä½Ž

### ðŸ“‹ è©³ç´°å®Ÿè¡Œè¨ˆç”»

#### ðŸ”¥ æœ€å„ªå…ˆï¼ˆå³æ™‚å®Ÿè¡Œ: 1-4é€±é–“ï¼‰
- [ ] **ã‚¢ã‚¯ã‚·ãƒ§ãƒ³1**: å…·ä½“çš„å†…å®¹ãƒ»æ‹…å½“ãƒ»æœŸé™ãƒ»æˆæžœç‰©
- [ ] **ã‚¢ã‚¯ã‚·ãƒ§ãƒ³2**: å…·ä½“çš„å†…å®¹ãƒ»æ‹…å½“ãƒ»æœŸé™ãƒ»æˆæžœç‰©

#### â­ é«˜å„ªå…ˆï¼ˆçŸ­æœŸå®Ÿè¡Œ: 1-3ãƒ¶æœˆï¼‰
- [ ] **ã‚¢ã‚¯ã‚·ãƒ§ãƒ³3**: å…·ä½“çš„å†…å®¹ãƒ»æ‹…å½“ãƒ»æœŸé™ãƒ»æˆæžœç‰©
- [ ] **ã‚¢ã‚¯ã‚·ãƒ§ãƒ³4**: å…·ä½“çš„å†…å®¹ãƒ»æ‹…å½“ãƒ»æœŸé™ãƒ»æˆæžœç‰©

#### ðŸ“ˆ ä¸­å„ªå…ˆï¼ˆä¸­æœŸå®Ÿè¡Œ: 3-6ãƒ¶æœˆï¼‰
- [ ] **ã‚¢ã‚¯ã‚·ãƒ§ãƒ³5**: å…·ä½“çš„å†…å®¹ãƒ»æ‹…å½“ãƒ»æœŸé™ãƒ»æˆæžœç‰©

#### ðŸŽ¯ é•·æœŸï¼ˆæˆ¦ç•¥å®Ÿè¡Œ: 6ãƒ¶æœˆä»¥ä¸Šï¼‰
- [ ] **ã‚¢ã‚¯ã‚·ãƒ§ãƒ³6**: å…·ä½“çš„å†…å®¹ãƒ»æ‹…å½“ãƒ»æœŸé™ãƒ»æˆæžœç‰©

### ðŸ“Š æœŸå¾…åŠ¹æžœãƒ»KPI
**å®šé‡çš„åŠ¹æžœ**
- å…·ä½“çš„ãªæ•°å€¤ç›®æ¨™
- æ¸¬å®šå¯èƒ½ãªæŒ‡æ¨™

**å®šæ€§çš„åŠ¹æžœ**  
- æ”¹å–„ã•ã‚Œã‚‹äº‹é …
- æ³¢åŠåŠ¹æžœ

**KPIè¨­å®š**
- æ¸¬å®šæŒ‡æ¨™ã¨ç›®æ¨™å€¤
- ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°æ–¹æ³•

### ðŸ’° å¿…è¦ãƒªã‚½ãƒ¼ã‚¹ãƒ»ä½“åˆ¶
- äººçš„ãƒªã‚½ãƒ¼ã‚¹
- äºˆç®—ãƒ»æŠ•è³‡
- ã‚·ã‚¹ãƒ†ãƒ ãƒ»ãƒ„ãƒ¼ãƒ«
- å¤–éƒ¨ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼

### âš ï¸ ãƒªã‚¹ã‚¯ãƒ»å¯¾ç­–
**ä¸»è¦ãƒªã‚¹ã‚¯**
- ãƒªã‚¹ã‚¯è¦å› ã®ç‰¹å®š
- å½±éŸ¿åº¦ã¨ç™ºç”Ÿç¢ºçŽ‡

**å¯¾ç­–ãƒ»è»½æ¸›ç­–**
- äºˆé˜²ç­–
- ç™ºç”Ÿæ™‚ã®å¯¾å¿œç­–

### ðŸ† æˆåŠŸè¦å› 
- æˆåŠŸã®ãŸã‚ã®é‡è¦ãƒã‚¤ãƒ³ãƒˆ
- æŽ¨é€²ä½“åˆ¶ãƒ»ã‚¬ãƒãƒŠãƒ³ã‚¹
- ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³æˆ¦ç•¥

ã€å‚ç…§ãƒ‡ãƒ¼ã‚¿ã€‘
{context}
"""
    }
    
    return prompts[analysis_type]

def display_reference_data_comprehensive(results):
    """åŒ…æ‹¬çš„å‚ç…§ãƒ‡ãƒ¼ã‚¿è¡¨ç¤ºï¼ˆGPT-4oå¯¾å¿œï¼‰"""
    
    with st.expander(f"ðŸ“š å‚ç…§ãƒ‡ãƒ¼ã‚¿è©³ç´°åˆ†æžï¼ˆ{len(results)}ä»¶ - GPT-4oå‡¦ç†æ¸ˆã¿ï¼‰"):
        
        # è©³ç´°çµ±è¨ˆæƒ…å ±
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            avg_similarity = sum([1-r['distance'] for r in results]) / len(results)
            st.metric("å¹³å‡é¡žä¼¼åº¦", f"{avg_similarity:.3f}")
        
        with col2:
            total_chars = sum([len(r['content']) for r in results])
            st.metric("ç·æ–‡å­—æ•°", f"{total_chars:,}")
        
        with col3:
            sources = {}
            for r in results:
                source = r['metadata'].get('source', 'ä¸æ˜Ž')
                sources[source] = sources.get(source, 0) + 1
            st.metric("ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹æ•°", len(sources))
        
        with col4:
            high_relevance = len([r for r in results if (1-r['distance']) > 0.7])
            st.metric("é«˜é–¢é€£åº¦æ–‡æ›¸", f"{high_relevance}ä»¶")
        
        # ã‚½ãƒ¼ã‚¹åˆ†å¸ƒ
        st.write("**ðŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹åˆ†å¸ƒ:**")
        for source, count in sources.items():
            percentage = (count / len(results)) * 100
            st.write(f"- {source}: {count}ä»¶ ({percentage:.1f}%)")
        
        # é–¢é€£åº¦åˆ†å¸ƒ
        st.write("**ðŸ“ˆ é–¢é€£åº¦åˆ†å¸ƒ:**")
        high_rel = len([r for r in results if (1-r['distance']) > 0.8])
        med_rel = len([r for r in results if 0.6 < (1-r['distance']) <= 0.8])
        low_rel = len([r for r in results if (1-r['distance']) <= 0.6])
        
        st.write(f"- é«˜é–¢é€£åº¦(0.8+): {high_rel}ä»¶")
        st.write(f"- ä¸­é–¢é€£åº¦(0.6-0.8): {med_rel}ä»¶") 
        st.write(f"- ä½Žé–¢é€£åº¦(0.6-): {low_rel}ä»¶")
        
        # ä¸Šä½å‚ç…§æ–‡æ›¸ï¼ˆè©³ç´°ç‰ˆï¼‰
        st.write("**ðŸ“„ ä¸Šä½å‚ç…§æ–‡æ›¸ï¼ˆè©³ç´°ç‰ˆï¼‰:**")
        for i, result in enumerate(results[:15]):  # ä¸Šä½15ä»¶
            title = result['metadata'].get('title', 'ç„¡é¡Œ')
            source = result['metadata'].get('source', 'ä¸æ˜Ž')
            similarity = 1 - result['distance']
            category = result.get('category', 'ä¸€èˆ¬')
            
            with st.expander(f"{i+1}. {title} ({source}) - é¡žä¼¼åº¦: {similarity:.3f}"):
                col_a, col_b = st.columns(2)
                with col_a:
                    st.write(f"**ã‚«ãƒ†ã‚´ãƒª**: {category}")
                    st.write(f"**é¡žä¼¼åº¦**: {similarity:.3f}")
                with col_b:
                    st.write(f"**ã‚½ãƒ¼ã‚¹**: {source}")
                    st.write(f"**æ–‡å­—æ•°**: {len(result['content'])}æ–‡å­—")
                
                # å†…å®¹ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
                content_preview = result['content'][:500] + "..." if len(result['content']) > 500 else result['content']
                st.text_area(f"å†…å®¹ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", content_preview, height=100, key=f"preview_{i}")

if __name__ == "__main__":
    main()
